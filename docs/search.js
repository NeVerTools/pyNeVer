window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "pynever", "modulename": "pynever", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.datasets", "modulename": "pynever.datasets", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.datasets.Dataset", "modulename": "pynever.datasets", "qualname": "Dataset", "kind": "class", "doc": "<p>An abstract class used to represent a Dataset. The concrete descendant must\nimplement the methods __getitem__ and __len__.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.datasets.TorchMNIST", "modulename": "pynever.datasets", "qualname": "TorchMNIST", "kind": "class", "doc": "<p>A concrete class used to represent the MNIST Dataset. It leverages the torch dataset MNIST.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>data_path : str\n    Path to the folder in which the dataset will be saved.\ntrain : bool\n    If True then the training set is loaded otherwise the test set is loaded.\ntransform : Callable, Optional\n    Transformation to apply to the data. We assume this is an object like the transforms presented in torchvision.\n    The parameters of the callable (other than the object subject to the transformation) should be attributes of\n    the object.\ntarget_transform : Callable, Optional\n    Transformation to apply to the targets. We assume this is an object like the transforms presented in\n    torchvision. The parameters of the callable (other than the object subject to the transformation) should be\n    attributes of the object.\ndownload : bool\n    True if the dataset must be downloaded, False otherwise.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "pynever.datasets.TorchMNIST.__init__", "modulename": "pynever.datasets", "qualname": "TorchMNIST.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">train</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">transform</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">target_transform</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">download</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.datasets.TorchFMNIST", "modulename": "pynever.datasets", "qualname": "TorchFMNIST", "kind": "class", "doc": "<p>A concrete class used to represent the FMNIST Dataset. It leverages the torch dataset FMNIST.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>data_path : str\n    Path to the folder in which the dataset will be saved.\ntrain : bool\n    If True then the training set is loaded otherwise the test set is loaded.\ntransform : Callable, Optional\n    Transformation to apply to the data. We assume this is an object like the transforms presented in torchvision.\n    The parameters of the callable (other than the object subject to the transformation) should be attributes of\n    the object.\ntarget_transform : Callable, Optional\n    Transformation to apply to the targets. We assume this is an object like the transforms presented in\n    torchvision. The parameters of the callable (other than the object subject to the transformation) should be\n    attributes of the object.\ndownload : bool\n    True if the dataset must be downloaded, False otherwise.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "pynever.datasets.TorchFMNIST.__init__", "modulename": "pynever.datasets", "qualname": "TorchFMNIST.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">train</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">transform</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">target_transform</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">download</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.datasets.GenericFileDataset", "modulename": "pynever.datasets", "qualname": "GenericFileDataset", "kind": "class", "doc": "<p>A concrete class used to represent a generic dataset memorized as a txt file. It loads the values using numpy\nloadtxt function. It assumes each line of the file is a separated datapoint.\nFor each line we assume that the first n values are the input and the following are the target. The index of the\nfirst element of the target is identified by the target_index attribute.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>filepath : str\n    Path to the file containing the dataset.\n    N.B.: the names of the dataset are supposed to be jame_pos_*.txt where * can be tested or train.\ntarget_index : int\n    Index of the first element of the outputs.\ndtype : type, Optional\n    Data type of the values of the data-points. Refer to numpy.loadtxt for more details.\ndelimiter : str, Optional\n    Delimiter between the different values of the data-points. Refer to numpy.loadtxt for more details.\ntransform : Callable, Optional\n    Transformation to apply to the data. We assume this is an object like the transforms presented in torchvision.\n    The parameters of the callable (other than the object subject to the transformation) should be attributes of\n    the object.\ntarget_transform : Callable, Optional\n    Transformation to apply to the targets. We assume this is an object like the transforms presented in\n    torchvision. The parameters of the callable (other than the object subject to the transformation) should be\n    attributes of the object.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "pynever.datasets.GenericFileDataset.__init__", "modulename": "pynever.datasets", "qualname": "GenericFileDataset.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filepath</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">target_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\tdtype: type = &lt;class &#x27;float&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">delimiter</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;,&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">transform</span><span class=\"p\">:</span> <span class=\"n\">Callable</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">target_transform</span><span class=\"p\">:</span> <span class=\"n\">Callable</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.datasets.GenericFileDataset.filepath", "modulename": "pynever.datasets", "qualname": "GenericFileDataset.filepath", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.datasets.GenericFileDataset.target_index", "modulename": "pynever.datasets", "qualname": "GenericFileDataset.target_index", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.datasets.GenericFileDataset.dtype", "modulename": "pynever.datasets", "qualname": "GenericFileDataset.dtype", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.datasets.GenericFileDataset.delimiter", "modulename": "pynever.datasets", "qualname": "GenericFileDataset.delimiter", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.datasets.GenericFileDataset.transform", "modulename": "pynever.datasets", "qualname": "GenericFileDataset.transform", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.datasets.GenericFileDataset.target_transform", "modulename": "pynever.datasets", "qualname": "GenericFileDataset.target_transform", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.datasets.DynamicsJamesPos", "modulename": "pynever.datasets", "qualname": "DynamicsJamesPos", "kind": "class", "doc": "<p>A concrete class used to represent the Dynamic James Dataset presented in the paper\n\"Challenging SMT solvers to verify neural networks\" by Pulina and Tacchella (2012).\nAutomatic download is at present not supported, therefore the dataset must be downloaded manually.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>data_path : str\n    Path to the folder containing the training set and the test set.\n    N.B.: the names of the dataset are supposed to be james_pos_*.txt where * can be tested or train.\ntrain : bool\n    If True then the training set is loaded otherwise the test set is loaded.\ntransform : Callable, Optional\n    Transformation to apply to the data. We assume this is an object like the transforms presented in torchvision.\n    The parameters of the callable (other than the object subject to the transformation) should be attributes of\n    the object.\ntarget_transform : Callable, Optional\n    Transformation to apply to the targets. We assume this is an object like the transforms presented in\n    torchvision. The parameters of the callable (other than the object subject to the transformation) should be\n    attributes of the object.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "pynever.datasets.DynamicsJamesPos.__init__", "modulename": "pynever.datasets", "qualname": "DynamicsJamesPos.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">train</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">transform</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">target_transform</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.networks", "modulename": "pynever.networks", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.networks.NeuralNetwork", "modulename": "pynever.networks", "qualname": "NeuralNetwork", "kind": "class", "doc": "<p>An abstract class used for our internal representation of a generic NeuralNetwork. It consists of a graph of LayerNodes\nand a list of AlternativeRepresentations. It should be noted that this data structure it is not able\nto compute the input-output relation defined by the network. The properties of the computational graph are\nspecialized in the concrete classes.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>nodes : dict <str, SingleInputLayerNode>\n    Dictionary containing str keys and LayerNodes values. It contains the nodes of the graph,\n    the identifier of the node of interest is used as a key in the nodes' dictionary.\nedges : dict <str, list <str>&gt;\n    Dictionary of identifiers of LayerNodes, it contains for each node identified by the keys, the list of nodes\n    connected to it.\nalt_rep_cache : List<AlternativeRepresentation>\n    Dictionary of containing str keys and AlternativeRepresentation values, it contains the\n    AlternativeRepresentations of out network.\nup_to_date : bool\n    Boolean Flag which shows if the internal representation is up-to-date with respect to the\n    AlternativeRepresentations.\nidentifier : str\n    Identifier of the Sequential Neural Network.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.networks.NeuralNetwork.__init__", "modulename": "pynever.networks", "qualname": "NeuralNetwork.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span></span>)</span>"}, {"fullname": "pynever.networks.NeuralNetwork.nodes", "modulename": "pynever.networks", "qualname": "NeuralNetwork.nodes", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.networks.NeuralNetwork.edges", "modulename": "pynever.networks", "qualname": "NeuralNetwork.edges", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.networks.NeuralNetwork.alt_rep_cache", "modulename": "pynever.networks", "qualname": "NeuralNetwork.alt_rep_cache", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.networks.NeuralNetwork.up_to_date", "modulename": "pynever.networks", "qualname": "NeuralNetwork.up_to_date", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.networks.NeuralNetwork.identifier", "modulename": "pynever.networks", "qualname": "NeuralNetwork.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.networks.SequentialNetwork", "modulename": "pynever.networks", "qualname": "SequentialNetwork", "kind": "class", "doc": "<p>Concrete children of NeuralNetwork representing a sequential NeuralNetwork. It consists of a graph of LayerNodes\nand a list of AlternativeRepresentations. It should be noted that this data structure it is not able\nto compute the input-output relation defined by the network. The computational graph of a SequentialNetwork must\ncorrespond to a standard list.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>input_id : str\n    Identifier for the input of the Sequential Neural Network.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>is_empty()\n    Procedure to check whether the network is empty.\nadd_node(SingleInputLayerNode)\n    Procedure to add a new SingleInputLayerNode to the sequential Neural Network.\nget_first_node()\n    Procedure to extract the first node of the sequential Neural Network.\nget_next_node(SingleInputLayerNode)\n    Procedure to get the next node of the network given an input SingleInputLayerNode.\nget_last_node()\n    Procedure to extract the last node of the sequential Neural Network.\ndelete_last_node()\n    Procedure to delete the last node of the sequential Neural Network.\nget_input_len()\n    Procedure to count the number of single inputs\nget_output_len()\n    Procedure to count the number of single outputs\ncount_relu_layers()\n    Procedure to extract the number of layers of the sequential Neural Network.</p>\n", "bases": "NeuralNetwork"}, {"fullname": "pynever.networks.SequentialNetwork.__init__", "modulename": "pynever.networks", "qualname": "SequentialNetwork.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">input_id</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "pynever.networks.SequentialNetwork.input_id", "modulename": "pynever.networks", "qualname": "SequentialNetwork.input_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.networks.SequentialNetwork.is_empty", "modulename": "pynever.networks", "qualname": "SequentialNetwork.is_empty", "kind": "function", "doc": "<p>Procedure to check whether the network is empty.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True if there are no nodes in the network, False otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.networks.SequentialNetwork.add_node", "modulename": "pynever.networks", "qualname": "SequentialNetwork.add_node", "kind": "function", "doc": "<p>Procedure to add a new SingleInputLayerNode. In sequential network the new node must be connected directly to the\nprevious node forming a list.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>node : SingleInputLayerNode\n    New node to add to the Sequential network.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">node</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">SingleInputLayerNode</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.networks.SequentialNetwork.get_first_node", "modulename": "pynever.networks", "qualname": "SequentialNetwork.get_first_node", "kind": "function", "doc": "<p>Procedure to get the first SingleInputLayerNode of the network.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>SingleInputLayerNode\n    The first node of the network.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">SingleInputLayerNode</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.networks.SequentialNetwork.get_next_node", "modulename": "pynever.networks", "qualname": "SequentialNetwork.get_next_node", "kind": "function", "doc": "<p>Procedure to get the next SingleInputLayerNode of the network given an input SingleInputLayerNode.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>SingleInputLayerNode\n    The next node of the network.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">node</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">SingleInputLayerNode</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">SingleInputLayerNode</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.networks.SequentialNetwork.get_last_node", "modulename": "pynever.networks", "qualname": "SequentialNetwork.get_last_node", "kind": "function", "doc": "<p>Procedure to get the last SingleInputLayerNode of the network.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>SingleInputLayerNode\n    The last node of the network.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">SingleInputLayerNode</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.networks.SequentialNetwork.delete_last_node", "modulename": "pynever.networks", "qualname": "SequentialNetwork.delete_last_node", "kind": "function", "doc": "<p>Procedure to remove the last SingleInputLayerNode from the network.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>SingleInputLayerNode\n    The last node of the network.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">SingleInputLayerNode</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.networks.SequentialNetwork.get_input_len", "modulename": "pynever.networks", "qualname": "SequentialNetwork.get_input_len", "kind": "function", "doc": "<p>Count the number of inputs in in_dim</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>int\n    The number of single inputs</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.networks.SequentialNetwork.get_output_len", "modulename": "pynever.networks", "qualname": "SequentialNetwork.get_output_len", "kind": "function", "doc": "<p>Count the number of outputs in out_dim</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>int\n    The number of single outputs</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.networks.SequentialNetwork.count_relu_layers", "modulename": "pynever.networks", "qualname": "SequentialNetwork.count_relu_layers", "kind": "function", "doc": "<p>Count the number of ReLU layers of the NN.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>int\n    The number of ReLU layers</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes", "modulename": "pynever.nodes", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.SingleInputLayerNode", "modulename": "pynever.nodes", "qualname": "SingleInputLayerNode", "kind": "class", "doc": "<p>An abstract class used for our internal representation of a generic Layer of a Neural Network.\nIts concrete children correspond to real network layers.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier of the SingleInputLayerNode.\nin_dim : Tuple\n    Dimension of the input Tensor as a tuple (ndarray.shape like).\nout_dim : Tuple\n    Dimension of the output Tensor as a tuple (ndarray.shape like).</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.nodes.SingleInputLayerNode.identifier", "modulename": "pynever.nodes", "qualname": "SingleInputLayerNode.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.SingleInputLayerNode.in_dim", "modulename": "pynever.nodes", "qualname": "SingleInputLayerNode.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.SingleInputLayerNode.out_dim", "modulename": "pynever.nodes", "qualname": "SingleInputLayerNode.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.SingleInputLayerNode.update_input", "modulename": "pynever.nodes", "qualname": "SingleInputLayerNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.ReLUNode", "modulename": "pynever.nodes", "qualname": "ReLUNode", "kind": "class", "doc": "<p>A class used for our internal representation of a ReLU Layer of a Neural Network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.ReLUNode.__init__", "modulename": "pynever.nodes", "qualname": "ReLUNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.nodes.ReLUNode.update_input", "modulename": "pynever.nodes", "qualname": "ReLUNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.ELUNode", "modulename": "pynever.nodes", "qualname": "ELUNode", "kind": "class", "doc": "<p>A class used for our internal representation of a ELU Layer of a Neural Network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>alpha : float, optional\n    The alpha value for the ELU formulation (default: 1.0).</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.ELUNode.__init__", "modulename": "pynever.nodes", "qualname": "ELUNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span></span>)</span>"}, {"fullname": "pynever.nodes.ELUNode.alpha", "modulename": "pynever.nodes", "qualname": "ELUNode.alpha", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ELUNode.update_input", "modulename": "pynever.nodes", "qualname": "ELUNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.CELUNode", "modulename": "pynever.nodes", "qualname": "CELUNode", "kind": "class", "doc": "<p>A class used for our internal representation of a CELU Layer of a Neural Network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>alpha : float, optional\n    The alpha value for the CELU formulation (default: 1.0).</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.CELUNode.__init__", "modulename": "pynever.nodes", "qualname": "CELUNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span></span>)</span>"}, {"fullname": "pynever.nodes.CELUNode.alpha", "modulename": "pynever.nodes", "qualname": "CELUNode.alpha", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.CELUNode.update_input", "modulename": "pynever.nodes", "qualname": "CELUNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.LeakyReLUNode", "modulename": "pynever.nodes", "qualname": "LeakyReLUNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Leaky ReLU Layer of a Neural Network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>negative_slope : float, optional\n    Controls the angle of the negative slope (default: 1e-2).</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.LeakyReLUNode.__init__", "modulename": "pynever.nodes", "qualname": "LeakyReLUNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">negative_slope</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.01</span></span>)</span>"}, {"fullname": "pynever.nodes.LeakyReLUNode.negative_slope", "modulename": "pynever.nodes", "qualname": "LeakyReLUNode.negative_slope", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.LeakyReLUNode.update_input", "modulename": "pynever.nodes", "qualname": "LeakyReLUNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.SigmoidNode", "modulename": "pynever.nodes", "qualname": "SigmoidNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Sigmoid Layer of a Neural Network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.SigmoidNode.__init__", "modulename": "pynever.nodes", "qualname": "SigmoidNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.nodes.SigmoidNode.update_input", "modulename": "pynever.nodes", "qualname": "SigmoidNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.TanhNode", "modulename": "pynever.nodes", "qualname": "TanhNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Tanh Layer of a Neural Network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.TanhNode.__init__", "modulename": "pynever.nodes", "qualname": "TanhNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.nodes.TanhNode.update_input", "modulename": "pynever.nodes", "qualname": "TanhNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.FullyConnectedNode", "modulename": "pynever.nodes", "qualname": "FullyConnectedNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Fully Connected layer of a Neural Network</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>in_features : int\n    Number of input features of the fully connected layer.\nout_features : int\n    Number of output features of the fully connected layer.\nweight : Tensor, optional\n    Tensor containing the weight parameters of the fully connected layer.\nbias : Tensor, optional\n    Tensor containing the bias parameters of the fully connected layer.\nhas_bias : bool, optional\n    Flag True if the fully connected layer has bias, False otherwise (default: True)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.FullyConnectedNode.__init__", "modulename": "pynever.nodes", "qualname": "FullyConnectedNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">weight</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">has_bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.nodes.FullyConnectedNode.in_features", "modulename": "pynever.nodes", "qualname": "FullyConnectedNode.in_features", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.FullyConnectedNode.out_features", "modulename": "pynever.nodes", "qualname": "FullyConnectedNode.out_features", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.FullyConnectedNode.weight", "modulename": "pynever.nodes", "qualname": "FullyConnectedNode.weight", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.FullyConnectedNode.has_bias", "modulename": "pynever.nodes", "qualname": "FullyConnectedNode.has_bias", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.FullyConnectedNode.bias", "modulename": "pynever.nodes", "qualname": "FullyConnectedNode.bias", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.FullyConnectedNode.update_input", "modulename": "pynever.nodes", "qualname": "FullyConnectedNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.BatchNormNode", "modulename": "pynever.nodes", "qualname": "BatchNormNode", "kind": "class", "doc": "<p>A class used for our internal representation of a one dimensional Batch Normalization Layer.\nN.B. There are some problem for compatibility between pytorch and onnx: pytorch provide 3 different kind\nof batchnorm layers which supports [(N, C) or (N, C, L)], (N, C, H, W) and (N, C, D, H, W) dimensional inputs\nrespectively (BatchNorm1D, BatchNorm2D and BatchNorm3D). The batchnorm operation is always applied to the\nC dimension (N is the batch dimension which we do not keep track of). ONNX accepts input in the form of\n(N, C, D1, ... , Dn) where N is the batch dimension and C is the dimension to which the batchnorm is applied.\nIt should also be noted that at present the pytorch constructors do not support the setting of weight and\nbias explicitly.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>num_features : int\n    Number of input and output feature of the Batch Normalization Layer.\nweight : Tensor, optional\n    Tensor containing the weight parameters of the Batch Normalization Layer. (default: None)\nbias : Tensor, optional\n    Tensor containing the bias parameter of the Batch Normalization Layer. (default: None)\nrunning_mean : Tensor, optional\n    Tensor containing the running mean parameter of the Batch Normalization Layer. (default: None)\nrunning_var : Tensor, optional\n    Tensor containing the running var parameter of the Batch Normalization Layer. (default: None)\neps : float, optional\n    Value added to the denominator for numerical stability (default: 1e-5).\nmomentum : float, optional\n    Value used for the running_mean and running_var computation. Can be set to None\n    for cumulative moving average (default: 0.1)\naffine : bool, optional\n    When set to True, the module has learnable affine parameter (default: True).\ntrack_running_stats : bool, optional\n    When set to True, the module tracks the running mean and variance, when set to false the module\n    does not track such statistics and always uses batch statistics in both training and eval modes (default: True).</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.BatchNormNode.__init__", "modulename": "pynever.nodes", "qualname": "BatchNormNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">weight</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">running_mean</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">running_var</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"n\">momentum</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">affine</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">track_running_stats</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.nodes.BatchNormNode.num_features", "modulename": "pynever.nodes", "qualname": "BatchNormNode.num_features", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.weight", "modulename": "pynever.nodes", "qualname": "BatchNormNode.weight", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.bias", "modulename": "pynever.nodes", "qualname": "BatchNormNode.bias", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.running_mean", "modulename": "pynever.nodes", "qualname": "BatchNormNode.running_mean", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.running_var", "modulename": "pynever.nodes", "qualname": "BatchNormNode.running_var", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.eps", "modulename": "pynever.nodes", "qualname": "BatchNormNode.eps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.momentum", "modulename": "pynever.nodes", "qualname": "BatchNormNode.momentum", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.affine", "modulename": "pynever.nodes", "qualname": "BatchNormNode.affine", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.track_running_stats", "modulename": "pynever.nodes", "qualname": "BatchNormNode.track_running_stats", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.BatchNormNode.update_input", "modulename": "pynever.nodes", "qualname": "BatchNormNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.ConvNode", "modulename": "pynever.nodes", "qualname": "ConvNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Convolutional layer of a Neural Network.\nAlso in this case the pytorch and onnx representation present incompatibilities. As in Batchnorm pytorch\nprovide 3 different class for convolution based on the dimensionality of the input considered.\nMoreover, the padding is forced to be symmetric.\nThe dimensionality supported for the input are (N, C, L), (N, C, H, W) and (N, C, D, H, W).\nIn ONNX the padding can be asymmetric and the dimensionality supported is (N, C, D1, ... , Dn) where D1, ... Dn are\nthe dimension on which the convolution is applied</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>in_channels : int\n    Number of input channels in Conv Layer.\nout_channels : int\n    Number of output channels in Conv Layer.\nkernel_size : Tuple\n    The size of the kernel. Should have size equal to the number of dimension n\n    (we don't count the channel dimension).\nstride : Tuple\n    Stride along each spatial axis. Should have size equal to the number of dimension n\n    (we don't count the channel dimension).\npadding : Tuple\n    Padding for the beginning and ending along each spatial axis.\n    Padding format should be as follows [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of\n    pixels added at the beginning of axis <code>i</code> and xi_end, the number of pixels added at the end of axis <code>i</code>.\n    Should have size equal to two times the number of dimension n (we don't count the channel dimension).\ndilation : Tuple\n    Dilation value along each spatial axis of the filter\ngroups : int\n    Number of groups input channels and output channels are divided into\nhas_bias : bool, optional\n    Flag True if the convolutional layer has bias, False otherwise (default: False)\nbias : Tensor, optional\n    Tensor containing the bias parameter of the Conv Layer (default: None)\nweight : Tensor, optional\n    Tensor containing the weight parameters of the Conv layer (default: None)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.ConvNode.__init__", "modulename": "pynever.nodes", "qualname": "ConvNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">groups</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">has_bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">weight</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.nodes.ConvNode.in_channels", "modulename": "pynever.nodes", "qualname": "ConvNode.in_channels", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.out_channels", "modulename": "pynever.nodes", "qualname": "ConvNode.out_channels", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.kernel_size", "modulename": "pynever.nodes", "qualname": "ConvNode.kernel_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.stride", "modulename": "pynever.nodes", "qualname": "ConvNode.stride", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.padding", "modulename": "pynever.nodes", "qualname": "ConvNode.padding", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.dilation", "modulename": "pynever.nodes", "qualname": "ConvNode.dilation", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.groups", "modulename": "pynever.nodes", "qualname": "ConvNode.groups", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.has_bias", "modulename": "pynever.nodes", "qualname": "ConvNode.has_bias", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.bias", "modulename": "pynever.nodes", "qualname": "ConvNode.bias", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.weight", "modulename": "pynever.nodes", "qualname": "ConvNode.weight", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ConvNode.update_input", "modulename": "pynever.nodes", "qualname": "ConvNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.AveragePoolNode", "modulename": "pynever.nodes", "qualname": "AveragePoolNode", "kind": "class", "doc": "<p>A class used for our internal representation of a AveragePool layer of a Neural Network.\nAlso in this case the pytorch and onnx representation present incompatibilities. As in Batchnorm pytorch\nprovide 3 different class for pooling based on the dimensionality of the input considered.\nMoreover, the padding is forced to be symmetric and the parameter divisor_override is present (it is not clear\nwhat is its effect). The dimensionality supported for the input are (N, C, L), (N, C, H, W) and (N, C, D, H, W).\nIn ONNX the padding can be asymmetric and the dimensionality supported is (N, C, D1, ... , Dn) where D1, ... Dn are\nthe dimension on which the pooling is applied</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>kernel_size : Tuple\n    The size of the kernel. Should have size equal to the number of dimension n\n    (we don't count the channel dimension).\nstride : Tuple\n    Stride along each spatial axis. Should have size equal to the number of dimension n\n    (we don't count the channel dimension).\npadding : Tuple\n    Padding for the beginning and ending along each spatial axis.\n    Padding format should be as follows [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of\n    pixels added at the beginning of axis <code>i</code> and xi_end, the number of pixels added at the end of axis <code>i</code>.\n    Should have size equal to two times the number of dimension n (we don't count the channel dimension).\nceil_mode : bool, optional\n    In order to use ceil mode. (default: False)\ncount_include_pad: bool, optional\n    Whether include pad pixels when calculating values for the edges (default: False)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.AveragePoolNode.__init__", "modulename": "pynever.nodes", "qualname": "AveragePoolNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">ceil_mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">count_include_pad</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "pynever.nodes.AveragePoolNode.kernel_size", "modulename": "pynever.nodes", "qualname": "AveragePoolNode.kernel_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.AveragePoolNode.stride", "modulename": "pynever.nodes", "qualname": "AveragePoolNode.stride", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.AveragePoolNode.padding", "modulename": "pynever.nodes", "qualname": "AveragePoolNode.padding", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.AveragePoolNode.ceil_mode", "modulename": "pynever.nodes", "qualname": "AveragePoolNode.ceil_mode", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.AveragePoolNode.count_include_pad", "modulename": "pynever.nodes", "qualname": "AveragePoolNode.count_include_pad", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.AveragePoolNode.update_input", "modulename": "pynever.nodes", "qualname": "AveragePoolNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.MaxPoolNode", "modulename": "pynever.nodes", "qualname": "MaxPoolNode", "kind": "class", "doc": "<p>A class used for our internal representation of a MaxPool layer of a Neural Network.\nAlso in this case the pytorch and onnx representation present incompatibilities. As in Batchnorm pytorch\nprovide 3 different class for pooling based on the dimensionality of the input considered.\nMoreover, the padding is forced to be symmetric. The dimensionality supported for the input\nare (N, C, L), (N, C, H, W) and (N, C, D, H, W).\nIn ONNX the padding can be asymmetric and the dimensionality supported is (N, C, D1, ... , Dn) where D1, ... Dn are\nthe dimension on which the pooling is applied</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>kernel_size : Tuple\n    The size of the kernel. Should have size equal to the number of dimension n\n    (we don't count the channel dimension).\nstride : Tuple\n    Stride along each spatial axis. Should have size equal to the number of dimension n\n    (we don't count the channel dimension).\npadding : Tuple\n    Padding for the beginning and ending along each spatial axis.\n    Padding format should be as follows [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of\n    pixels added at the beginning of axis <code>i</code> and xi_end, the number of pixels added at the end of axis <code>i</code>.\n    Should have size equal to two times the number of dimension n (we don't count the channel dimension).\ndilation : Tuple\n    Dilation value along each spatial axis of the filter\nceil_mode : bool, optional\n    In order to use ceil mode. (default: False)\nreturn_indices: bool\n    If True it will return the max indices along with the outputs (default: False)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.MaxPoolNode.__init__", "modulename": "pynever.nodes", "qualname": "MaxPoolNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">ceil_mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_indices</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "pynever.nodes.MaxPoolNode.kernel_size", "modulename": "pynever.nodes", "qualname": "MaxPoolNode.kernel_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.MaxPoolNode.stride", "modulename": "pynever.nodes", "qualname": "MaxPoolNode.stride", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.MaxPoolNode.padding", "modulename": "pynever.nodes", "qualname": "MaxPoolNode.padding", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.MaxPoolNode.ceil_mode", "modulename": "pynever.nodes", "qualname": "MaxPoolNode.ceil_mode", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.MaxPoolNode.return_indices", "modulename": "pynever.nodes", "qualname": "MaxPoolNode.return_indices", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.MaxPoolNode.dilation", "modulename": "pynever.nodes", "qualname": "MaxPoolNode.dilation", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.MaxPoolNode.update_input", "modulename": "pynever.nodes", "qualname": "MaxPoolNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.LRNNode", "modulename": "pynever.nodes", "qualname": "LRNNode", "kind": "class", "doc": "<p>A class used for our internal representation of a LocalResponseNormalization Layer of a Neural Network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>size : int\n    Amount of neighbouring channels used for normalization\nalpha : float, optional\n    Multiplicative factor (default: 0.0001)\nbeta : float, optional\n    Exponent. (default: 0.75)\nk : float, optional\n    Additive factor (default: 1.0)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.LRNNode.__init__", "modulename": "pynever.nodes", "qualname": "LRNNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0001</span>,</span><span class=\"param\">\t<span class=\"n\">beta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.75</span>,</span><span class=\"param\">\t<span class=\"n\">k</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span></span>)</span>"}, {"fullname": "pynever.nodes.LRNNode.size", "modulename": "pynever.nodes", "qualname": "LRNNode.size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.LRNNode.alpha", "modulename": "pynever.nodes", "qualname": "LRNNode.alpha", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.LRNNode.beta", "modulename": "pynever.nodes", "qualname": "LRNNode.beta", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.LRNNode.k", "modulename": "pynever.nodes", "qualname": "LRNNode.k", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.LRNNode.update_input", "modulename": "pynever.nodes", "qualname": "LRNNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.SoftMaxNode", "modulename": "pynever.nodes", "qualname": "SoftMaxNode", "kind": "class", "doc": "<p>A class used for our internal representation of a SoftMax Layer of a Neural Network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>axis : int, optional\n    A dimension along which Softmax will be computed (so every slice along dim will sum to 1)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.SoftMaxNode.__init__", "modulename": "pynever.nodes", "qualname": "SoftMaxNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">axis</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span></span>)</span>"}, {"fullname": "pynever.nodes.SoftMaxNode.axis", "modulename": "pynever.nodes", "qualname": "SoftMaxNode.axis", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.SoftMaxNode.update_input", "modulename": "pynever.nodes", "qualname": "SoftMaxNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.UnsqueezeNode", "modulename": "pynever.nodes", "qualname": "UnsqueezeNode", "kind": "class", "doc": "<p>A class used for our internal representation of an Unsqueeze Layer.\nWe follow the ONNX operator convention for attributes and definitions.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>axes : Tuple\n    List of indices at which to insert the singleton dimension.</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.UnsqueezeNode.__init__", "modulename": "pynever.nodes", "qualname": "UnsqueezeNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">axes</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.nodes.UnsqueezeNode.axes", "modulename": "pynever.nodes", "qualname": "UnsqueezeNode.axes", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.UnsqueezeNode.update_input", "modulename": "pynever.nodes", "qualname": "UnsqueezeNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.ReshapeNode", "modulename": "pynever.nodes", "qualname": "ReshapeNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Reshape layer of a Neural Network.\nWe follow the ONNX operator convention for attributes and definitions.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>shape : Tuple\n    Tuple which specifies the output shape\nallow_zero : bool, optional\n    By default, when any value in the 'shape' input is equal to zero the corresponding dimension value\n    is copied from the input tensor dynamically. allowzero=1 indicates that if any value in the 'shape' input is\n    set to zero, the zero value is honored, similar to NumPy. (default: False)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.ReshapeNode.__init__", "modulename": "pynever.nodes", "qualname": "ReshapeNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">shape</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">allow_zero</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "pynever.nodes.ReshapeNode.shape", "modulename": "pynever.nodes", "qualname": "ReshapeNode.shape", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ReshapeNode.allow_zero", "modulename": "pynever.nodes", "qualname": "ReshapeNode.allow_zero", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.ReshapeNode.update_input", "modulename": "pynever.nodes", "qualname": "ReshapeNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.FlattenNode", "modulename": "pynever.nodes", "qualname": "FlattenNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Flatten layer of a Neural Network. We follow the ONNX operator\nconvention for attributes and definitions.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>axis : int, optional\n    Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output.\n    The value for axis must be in the range [-r, r], where r is the rank of the input tensor. Negative value\n    means counting dimensions from the back. When axis = 0, the shape of the output tensor is\n    (1, (d_0 X d_1 ... d_n)), where the shape of the input tensor is (d_0, d_1, ... d_n).\n    N.B: it works assuming the initial batch dimension. (default: 0)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.FlattenNode.__init__", "modulename": "pynever.nodes", "qualname": "FlattenNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">axis</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span>)</span>"}, {"fullname": "pynever.nodes.FlattenNode.axis", "modulename": "pynever.nodes", "qualname": "FlattenNode.axis", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.FlattenNode.update_input", "modulename": "pynever.nodes", "qualname": "FlattenNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.DropoutNode", "modulename": "pynever.nodes", "qualname": "DropoutNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Dropout Layer of a Neural Network.\nThe inplace parameter of pytorch and the seed attribute and training_mode of onnx are not supported.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>p : float, optional\n    Probability of an element to be zeroed (default: 0.5)</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.DropoutNode.__init__", "modulename": "pynever.nodes", "qualname": "DropoutNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.5</span></span>)</span>"}, {"fullname": "pynever.nodes.DropoutNode.p", "modulename": "pynever.nodes", "qualname": "DropoutNode.p", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.DropoutNode.update_input", "modulename": "pynever.nodes", "qualname": "DropoutNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.nodes.TransposeNode", "modulename": "pynever.nodes", "qualname": "TransposeNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Dropout Layer of a Neural Network.\nThe inplace parameter of pytorch and the seed attribute and training_mode of onnx are not supported.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>perm : list, optional\n    Permutation to apply to the input dimsensions</p>\n", "bases": "SingleInputLayerNode"}, {"fullname": "pynever.nodes.TransposeNode.__init__", "modulename": "pynever.nodes", "qualname": "TransposeNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">perm</span><span class=\"p\">:</span> <span class=\"nb\">list</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.nodes.TransposeNode.perm", "modulename": "pynever.nodes", "qualname": "TransposeNode.perm", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.nodes.TransposeNode.update_input", "modulename": "pynever.nodes", "qualname": "TransposeNode.update_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.pytorch_layers", "modulename": "pynever.pytorch_layers", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Sequential", "modulename": "pynever.pytorch_layers", "qualname": "Sequential", "kind": "class", "doc": "<p>Custom representation of pytorch Sequential Network. It adds the identifier for the network and for the input</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the network\ninput_id : str\n    Identifier for the input of the network</p>\n", "bases": "torch.nn.modules.container.Sequential"}, {"fullname": "pynever.pytorch_layers.Sequential.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Sequential.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">input_id</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">modules</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Sequential.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Sequential.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Sequential.input_id", "modulename": "pynever.pytorch_layers", "qualname": "Sequential.input_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.ReLU", "modulename": "pynever.pytorch_layers", "qualname": "ReLU", "kind": "class", "doc": "<p>Custom representation of pytorch ReLU Layer. It adds the identifier for the node, the input size and the output\nsize.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.activation.ReLU"}, {"fullname": "pynever.pytorch_layers.ReLU.__init__", "modulename": "pynever.pytorch_layers", "qualname": "ReLU.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.ReLU.identifier", "modulename": "pynever.pytorch_layers", "qualname": "ReLU.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.ReLU.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "ReLU.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.ReLU.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "ReLU.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.ELU", "modulename": "pynever.pytorch_layers", "qualname": "ELU", "kind": "class", "doc": "<p>Custom representation of pytorch ELU Layer. It adds the identifier for the node, the input size and the output\nsize.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.activation.ELU"}, {"fullname": "pynever.pytorch_layers.ELU.__init__", "modulename": "pynever.pytorch_layers", "qualname": "ELU.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.ELU.identifier", "modulename": "pynever.pytorch_layers", "qualname": "ELU.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.ELU.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "ELU.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.ELU.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "ELU.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.LeakyReLU", "modulename": "pynever.pytorch_layers", "qualname": "LeakyReLU", "kind": "class", "doc": "<p>Custom representation of pytorch LeakyReLU Layer. It adds the identifier for the node, the input size and the output\nsize.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.activation.LeakyReLU"}, {"fullname": "pynever.pytorch_layers.LeakyReLU.__init__", "modulename": "pynever.pytorch_layers", "qualname": "LeakyReLU.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">negative_slope</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.LeakyReLU.identifier", "modulename": "pynever.pytorch_layers", "qualname": "LeakyReLU.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.LeakyReLU.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "LeakyReLU.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.LeakyReLU.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "LeakyReLU.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.CELU", "modulename": "pynever.pytorch_layers", "qualname": "CELU", "kind": "class", "doc": "<p>Custom representation of pytorch CELU Layer. It adds the identifier for the node, the input size and the output\nsize.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.activation.CELU"}, {"fullname": "pynever.pytorch_layers.CELU.__init__", "modulename": "pynever.pytorch_layers", "qualname": "CELU.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.CELU.identifier", "modulename": "pynever.pytorch_layers", "qualname": "CELU.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.CELU.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "CELU.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.CELU.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "CELU.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Sigmoid", "modulename": "pynever.pytorch_layers", "qualname": "Sigmoid", "kind": "class", "doc": "<p>Custom representation of pytorch Sigmoid Layer. It adds the identifier for the node, the input size and the output\nsize.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.activation.Sigmoid"}, {"fullname": "pynever.pytorch_layers.Sigmoid.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Sigmoid.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Sigmoid.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Sigmoid.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Sigmoid.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Sigmoid.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Sigmoid.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Sigmoid.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Tanh", "modulename": "pynever.pytorch_layers", "qualname": "Tanh", "kind": "class", "doc": "<p>Custom representation of pytorch Tanh Layer. It adds the identifier for the node, the input size and the output\nsize.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.activation.Tanh"}, {"fullname": "pynever.pytorch_layers.Tanh.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Tanh.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Tanh.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Tanh.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Tanh.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Tanh.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Tanh.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Tanh.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Hardtanh", "modulename": "pynever.pytorch_layers", "qualname": "Hardtanh", "kind": "class", "doc": "<p>Custom representation of pytorch Hardtanh Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.activation.Hardtanh"}, {"fullname": "pynever.pytorch_layers.Hardtanh.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Hardtanh.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">min_val</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">max_val</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Hardtanh.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Hardtanh.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Hardtanh.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Hardtanh.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Hardtanh.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Hardtanh.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Linear", "modulename": "pynever.pytorch_layers", "qualname": "Linear", "kind": "class", "doc": "<p>Custom representation of pytorch Linear Layer. It adds the identifier for the node, the input size and the output\nsize.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.linear.Linear"}, {"fullname": "pynever.pytorch_layers.Linear.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Linear.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">in_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">out_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Linear.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Linear.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Linear.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Linear.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Linear.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Linear.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm1d", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm1d", "kind": "class", "doc": "<p>Custom representation of pytorch BatchNorm1d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.batchnorm.BatchNorm1d"}, {"fullname": "pynever.pytorch_layers.BatchNorm1d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm1d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">num_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"n\">momentum</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">affine</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">track_running_stats</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.BatchNorm1d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm1d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm1d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm1d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm1d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm1d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm2d", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm2d", "kind": "class", "doc": "<p>Custom representation of pytorch BatchNorm2d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.batchnorm.BatchNorm2d"}, {"fullname": "pynever.pytorch_layers.BatchNorm2d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm2d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">num_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"n\">momentum</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">affine</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">track_running_stats</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.BatchNorm2d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm2d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm2d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm2d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm2d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm2d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm3d", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm3d", "kind": "class", "doc": "<p>Custom representation of pytorch BatchNorm3d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.batchnorm.BatchNorm3d"}, {"fullname": "pynever.pytorch_layers.BatchNorm3d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm3d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">num_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"n\">momentum</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">affine</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">track_running_stats</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.BatchNorm3d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm3d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm3d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm3d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.BatchNorm3d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "BatchNorm3d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv1d", "modulename": "pynever.pytorch_layers", "qualname": "Conv1d", "kind": "class", "doc": "<p>Custom representation of pytorch Conv1d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.conv.Conv1d"}, {"fullname": "pynever.pytorch_layers.Conv1d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Conv1d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">in_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">out_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">groups</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Conv1d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Conv1d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv1d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Conv1d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv1d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Conv1d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv2d", "modulename": "pynever.pytorch_layers", "qualname": "Conv2d", "kind": "class", "doc": "<p>Custom representation of pytorch Conv2d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.conv.Conv2d"}, {"fullname": "pynever.pytorch_layers.Conv2d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Conv2d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">in_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">out_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">groups</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Conv2d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Conv2d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv2d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Conv2d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv2d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Conv2d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv3d", "modulename": "pynever.pytorch_layers", "qualname": "Conv3d", "kind": "class", "doc": "<p>Custom representation of pytorch Conv3d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.conv.Conv3d"}, {"fullname": "pynever.pytorch_layers.Conv3d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Conv3d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">in_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">out_channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">groups</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Conv3d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Conv3d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv3d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Conv3d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Conv3d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Conv3d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool1d", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool1d", "kind": "class", "doc": "<p>Custom representation of pytorch AvgPool1d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.pooling.AvgPool1d"}, {"fullname": "pynever.pytorch_layers.AvgPool1d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool1d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">ceil_mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">count_include_pad</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.AvgPool1d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool1d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool1d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool1d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool1d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool1d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool2d", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool2d", "kind": "class", "doc": "<p>Custom representation of pytorch AvgPool2d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.pooling.AvgPool2d"}, {"fullname": "pynever.pytorch_layers.AvgPool2d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool2d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">ceil_mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">count_include_pad</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.AvgPool2d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool2d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool2d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool2d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool2d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool2d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool3d", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool3d", "kind": "class", "doc": "<p>Custom representation of pytorch AvgPool3d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.pooling.AvgPool3d"}, {"fullname": "pynever.pytorch_layers.AvgPool3d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool3d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">ceil_mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">count_include_pad</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.AvgPool3d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool3d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool3d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool3d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.AvgPool3d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "AvgPool3d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool1d", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool1d", "kind": "class", "doc": "<p>Custom representation of pytorch MaxPool1d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.pooling.MaxPool1d"}, {"fullname": "pynever.pytorch_layers.MaxPool1d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool1d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">return_indices</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">ceil_mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.MaxPool1d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool1d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool1d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool1d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool1d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool1d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool2d", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool2d", "kind": "class", "doc": "<p>Custom representation of pytorch MaxPool2d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.pooling.MaxPool2d"}, {"fullname": "pynever.pytorch_layers.MaxPool2d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool2d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">return_indices</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">ceil_mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.MaxPool2d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool2d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool2d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool2d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool2d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool2d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool3d", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool3d", "kind": "class", "doc": "<p>Custom representation of pytorch MaxPool3d Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.pooling.MaxPool3d"}, {"fullname": "pynever.pytorch_layers.MaxPool3d.__init__", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool3d.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">return_indices</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">ceil_mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.MaxPool3d.identifier", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool3d.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool3d.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool3d.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.MaxPool3d.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "MaxPool3d.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.LocalResponseNorm", "modulename": "pynever.pytorch_layers", "qualname": "LocalResponseNorm", "kind": "class", "doc": "<p>Custom representation of pytorch LocalResponseNorm Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.normalization.LocalResponseNorm"}, {"fullname": "pynever.pytorch_layers.LocalResponseNorm.__init__", "modulename": "pynever.pytorch_layers", "qualname": "LocalResponseNorm.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>,</span><span class=\"param\">\t<span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">beta</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">k</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.LocalResponseNorm.identifier", "modulename": "pynever.pytorch_layers", "qualname": "LocalResponseNorm.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.LocalResponseNorm.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "LocalResponseNorm.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.LocalResponseNorm.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "LocalResponseNorm.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Softmax", "modulename": "pynever.pytorch_layers", "qualname": "Softmax", "kind": "class", "doc": "<p>Custom representation of pytorch Softmax Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.activation.Softmax"}, {"fullname": "pynever.pytorch_layers.Softmax.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Softmax.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Softmax.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Softmax.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Softmax.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Softmax.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Softmax.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Softmax.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Dropout", "modulename": "pynever.pytorch_layers", "qualname": "Dropout", "kind": "class", "doc": "<p>Custom representation of pytorch Dropout Layer. It adds the identifier for the node,\nthe input size and the output size.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output</p>\n", "bases": "torch.nn.modules.dropout.Dropout"}, {"fullname": "pynever.pytorch_layers.Dropout.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Dropout.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">p</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Dropout.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Dropout.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Dropout.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Dropout.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Dropout.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Dropout.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Unsqueeze", "modulename": "pynever.pytorch_layers", "qualname": "Unsqueeze", "kind": "class", "doc": "<p>Custom class for pytorch Unsqueeze layer. It conforms to our representation and ONNX.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output\naxes : Tuple\n    List of indices at which to insert the singleton dimension.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "pynever.pytorch_layers.Unsqueeze.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Unsqueeze.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">axes</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Unsqueeze.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Unsqueeze.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Unsqueeze.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Unsqueeze.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Unsqueeze.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Unsqueeze.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Unsqueeze.axes", "modulename": "pynever.pytorch_layers", "qualname": "Unsqueeze.axes", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Unsqueeze.forward", "modulename": "pynever.pytorch_layers", "qualname": "Unsqueeze.forward", "kind": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.pytorch_layers.Reshape", "modulename": "pynever.pytorch_layers", "qualname": "Reshape", "kind": "class", "doc": "<p>Custom class for pytorch Reshape layer. It conforms to our representation and ONNX.\nTorch reshape function does not support zeros in the shape, therefore it cannot support the allow_zero attribute\nof our representation.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output\nshape : Tuple\n    Tuple which specifies the output shape</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "pynever.pytorch_layers.Reshape.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Reshape.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">shape</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Reshape.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Reshape.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Reshape.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Reshape.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Reshape.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Reshape.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Reshape.shape", "modulename": "pynever.pytorch_layers", "qualname": "Reshape.shape", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Reshape.forward", "modulename": "pynever.pytorch_layers", "qualname": "Reshape.forward", "kind": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.pytorch_layers.Flatten", "modulename": "pynever.pytorch_layers", "qualname": "Flatten", "kind": "class", "doc": "<p>Custom class for pytorch Flatten layer. It conforms to our representation and ONNX.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier for the node\nin_dim : Tuple\n    Tuple expressing the dimension of the input\nout_dim : Tuple\n    Tuple expressing the dimension of the output\naxis : int\n    Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output.\n    The value for axis must be in the range [-r, r], where r is the rank of the input tensor. Negative value\n    means counting dimensions from the back. Pytorch works assuming the presence of a batch dimension\n    for its tensor therefore we set the default to 1 so that the batch dimension is preserved.(default: 1)</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "pynever.pytorch_layers.Flatten.__init__", "modulename": "pynever.pytorch_layers", "qualname": "Flatten.__init__", "kind": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">in_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">out_dim</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span>, </span><span class=\"param\"><span class=\"n\">axis</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span></span>)</span>"}, {"fullname": "pynever.pytorch_layers.Flatten.identifier", "modulename": "pynever.pytorch_layers", "qualname": "Flatten.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Flatten.in_dim", "modulename": "pynever.pytorch_layers", "qualname": "Flatten.in_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Flatten.out_dim", "modulename": "pynever.pytorch_layers", "qualname": "Flatten.out_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Flatten.axis", "modulename": "pynever.pytorch_layers", "qualname": "Flatten.axis", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.pytorch_layers.Flatten.forward", "modulename": "pynever.pytorch_layers", "qualname": "Flatten.forward", "kind": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.scripts", "modulename": "pynever.scripts", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.scripts.cli", "modulename": "pynever.scripts.cli", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.scripts.cli.logger", "modulename": "pynever.scripts.cli", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger pynever.strategies.verification (INFO)&gt;"}, {"fullname": "pynever.scripts.cli.verify_single_model", "modulename": "pynever.scripts.cli", "qualname": "verify_single_model", "kind": "function", "doc": "<p>This method starts the verification procedure on the network model\nprovided in the model_file path and prints the result</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>safety_prop : bool\n    Specifies if the property is for safe or unsafe zone\nmodel_file : str\n    Path to the .onnx file of the network\nproperty_file : str\n    Path to the .vnnlib or .smt2 file of the property\nstrategy : str\n    Verification strategy (either complete, approximate, mixed)\nlogfile : str\n    Path to CSV file output</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True if the network is safe, False otherwise</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">safety_prop</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">model_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">property_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">strategy</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">logfile</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.scripts.cli.verify_CSV_batch", "modulename": "pynever.scripts.cli", "qualname": "verify_CSV_batch", "kind": "function", "doc": "<p>This method starts the verification procedure on the network model\nprovided in the model_file path and prints the result</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>safety_prop : bool\n    Specifies if the property is for safe or unsafe zone\ncsv_file : str\n    Path to the .csv file of the instances\nstrategy : str\n    Verification strategy (either complete, approximate, mixed)\nlogfile : str\n    Path to CSV file output</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True if all the instances executed, False otherwise</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">safety_prop</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>, </span><span class=\"param\"><span class=\"n\">csv_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">strategy</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">logfile</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.scripts.cli.reformat_counterexample", "modulename": "pynever.scripts.cli", "qualname": "reformat_counterexample", "kind": "function", "doc": "<p>This method writes the tensor data in a nice way for printing</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">counterexample</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.scripts.cli.neg_post_condition", "modulename": "pynever.scripts.cli", "qualname": "neg_post_condition", "kind": "function", "doc": "<p>This method negates the property post-condition in order\nto represent both safety and unsafety properties</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>prop_path : str\n    Path to the property file</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">prop_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies", "modulename": "pynever.strategies", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction", "modulename": "pynever.strategies.abstraction", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.logger_empty", "modulename": "pynever.strategies.abstraction", "qualname": "logger_empty", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger pynever.strategies.abstraction.empty_times (WARNING)&gt;"}, {"fullname": "pynever.strategies.abstraction.logger_lp", "modulename": "pynever.strategies.abstraction", "qualname": "logger_lp", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger pynever.strategies.abstraction.lp_times (WARNING)&gt;"}, {"fullname": "pynever.strategies.abstraction.logger_lb", "modulename": "pynever.strategies.abstraction", "qualname": "logger_lb", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger pynever.strategies.abstraction.lb_times (WARNING)&gt;"}, {"fullname": "pynever.strategies.abstraction.logger_ub", "modulename": "pynever.strategies.abstraction", "qualname": "logger_ub", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger pynever.strategies.abstraction.ub_times (WARNING)&gt;"}, {"fullname": "pynever.strategies.abstraction.parallel", "modulename": "pynever.strategies.abstraction", "qualname": "parallel", "kind": "variable", "doc": "<p></p>\n", "default_value": "True"}, {"fullname": "pynever.strategies.abstraction.AbsElement", "modulename": "pynever.strategies.abstraction", "qualname": "AbsElement", "kind": "class", "doc": "<p>An abstract class used for our internal representation of a generic Abstract Element (e.g., interval, zonotope,\npolyhedra etc.)</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier of the AbsElement.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.abstraction.AbsElement.__init__", "modulename": "pynever.strategies.abstraction", "qualname": "AbsElement.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.strategies.abstraction.Star", "modulename": "pynever.strategies.abstraction", "qualname": "Star", "kind": "class", "doc": "<p>A concrete class used for our internal representation of a Star.\nThe Star is defined as {x | x = c + Va such that Ca &lt;= d}\nwhere c is a n-dimensional vector corresponding to the center of the Star.\nV is the n-by-m matrix composed by the basis vectors.\na is the vector of m variables, C (p-by-m) and d (p-dim) are the matrix and the biases\ndefining a set of constraints.</p>\n\n<p>We refer to <Star-Based Reachability Analysis of Deep Neural Networks>\n(<a href=\"https://link.springer.com/chapter/10.1007/978-3-030-30942-8_39\">https://link.springer.com/chapter/10.1007/978-3-030-30942-8_39</a>) for details.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>center : Tensor\n    Center of the Star.\nbasis_matrix : Tensor\n    Matrix composed by the basis vectors of the Star\npredicate_matrix : Tensor\n    Matrix of the Predicate.\npredicate_bias : Tensor\n    Bias of the Predicate.\nubs : list\n    Upper bounds of the points defined by the Star.\nlbs : list\n    Lower bounds of the points defined by the Star.\nis_empty : bool\n    Boolean flag: True if the Star defines an empty set of points, False otherwise</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>get_bounds()\n    Function used to get the upper and lower bounds of the n variables of the star.\ncheck_if_empty()\n    Function used to check if the star corresponds to an empty set.</p>\n"}, {"fullname": "pynever.strategies.abstraction.Star.__init__", "modulename": "pynever.strategies.abstraction", "qualname": "Star.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">predicate_matrix</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">predicate_bias</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">center</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">basis_matrix</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">is_empty</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.strategies.abstraction.Star.predicate_matrix", "modulename": "pynever.strategies.abstraction", "qualname": "Star.predicate_matrix", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.Star.predicate_bias", "modulename": "pynever.strategies.abstraction", "qualname": "Star.predicate_bias", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.Star.lbs", "modulename": "pynever.strategies.abstraction", "qualname": "Star.lbs", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.Star.ubs", "modulename": "pynever.strategies.abstraction", "qualname": "Star.ubs", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.Star.is_empty", "modulename": "pynever.strategies.abstraction", "qualname": "Star.is_empty", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.Star.check_if_empty", "modulename": "pynever.strategies.abstraction", "qualname": "Star.check_if_empty", "kind": "function", "doc": "<p>Function used to check if the set of points defined by the star is empty.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>bool\n    True if the star defines an empty set of points, False otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.Star.get_bounds", "modulename": "pynever.strategies.abstraction", "qualname": "Star.get_bounds", "kind": "function", "doc": "<p>Function used to get the upper and lower bounds of the n variables of the star.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>(float, float)\n    Tuple containing the lower and upper bounds of the variable i of the star</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">i</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.Star.check_alpha_inside", "modulename": "pynever.strategies.abstraction", "qualname": "Star.check_alpha_inside", "kind": "function", "doc": "<p>Function which checks if the alpha point passed as input is valid with respect to the constraints defined by the\npredicate matrix and bias of the star.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>alpha_point : Tensor\n    Point (with respect ot the predicate variables) whose validity is to test.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    The result of the check as a boolean (True if the point is valid, False otherwise)</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">alpha_point</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.Star.check_point_inside", "modulename": "pynever.strategies.abstraction", "qualname": "Star.check_point_inside", "kind": "function", "doc": "<p>Function which checks if the point passed as input is valid with respect to the constraints defined by the\npredicate matrix and bias of the star.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>point : Tensor\n    Point whose validity is to test.\nepsilon : float\n    Acceptable deviation from real point.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    The result of the check as a boolean (True if the point is valid, False otherwise)</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">point</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.Star.get_samples", "modulename": "pynever.strategies.abstraction", "qualname": "Star.get_samples", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">num_samples</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">reset_auxiliary</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">new_start</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.StarSet", "modulename": "pynever.strategies.abstraction", "qualname": "StarSet", "kind": "class", "doc": "<p>Concrete class for our internal representation of a StarSet abstract element. A StarSet consist in a set\nof Star objects.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>stars : Set[Star]\n    Set of Star objects.</p>\n", "bases": "AbsElement"}, {"fullname": "pynever.strategies.abstraction.StarSet.__init__", "modulename": "pynever.strategies.abstraction", "qualname": "StarSet.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">stars</span><span class=\"p\">:</span> <span class=\"n\">Set</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.strategies.abstraction.intersect_with_halfspace", "modulename": "pynever.strategies.abstraction", "qualname": "intersect_with_halfspace", "kind": "function", "doc": "<p>Function which takes as input a Star and a halfspace defined by its coefficient matrix and bias vector\nand returns the Star resulting from the intersection of the input Star with the halfspace.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">star</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span>,</span><span class=\"param\">\t<span class=\"n\">coef_mat</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">bias_mat</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.mixed_single_relu_forward", "modulename": "pynever.strategies.abstraction", "qualname": "mixed_single_relu_forward", "kind": "function", "doc": "<p>Utility function for the management of the forward for AbsReLUNode. It is outside\nthe class scope since multiprocessing does not support parallelization with\nfunction internal to classes.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">star</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span>,</span><span class=\"param\">\t<span class=\"n\">heuristic</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">params</span><span class=\"p\">:</span> <span class=\"n\">List</span>,</span><span class=\"param\">\t<span class=\"n\">layer_bounds</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">bounds</span><span class=\"o\">.</span><span class=\"n\">AbstractBounds</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">Set</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span><span class=\"p\">],</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.single_fc_forward", "modulename": "pynever.strategies.abstraction", "qualname": "single_fc_forward", "kind": "function", "doc": "<p>Utility function for the management of the forward for AbsFullyConnectedNode. It is outside\nthe class scope since multiprocessing does not support parallelization with\nfunction internal to classes.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">star</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span>,</span><span class=\"param\">\t<span class=\"n\">weight</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Set</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.sig", "modulename": "pynever.strategies.abstraction", "qualname": "sig", "kind": "function", "doc": "<p>Utility function computing the logistic function of the input.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.sig_fod", "modulename": "pynever.strategies.abstraction", "qualname": "sig_fod", "kind": "function", "doc": "<p>Utility function computing the first order derivative of the logistic function of the input.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.area_sig_triangle", "modulename": "pynever.strategies.abstraction", "qualname": "area_sig_triangle", "kind": "function", "doc": "<p>Utility function computing the area of the triangle defined by an upper bound and a lower bound on the\nlogistic function. In particular is the triangle composed by the two tangents and line passing by the two bounds.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lb</span><span class=\"p\">:</span> <span class=\"nb\">float</span>, </span><span class=\"param\"><span class=\"n\">ub</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.single_sigmoid_forward", "modulename": "pynever.strategies.abstraction", "qualname": "single_sigmoid_forward", "kind": "function", "doc": "<p>Utility function for the management of the forward for AbsSigmoidNode. It is outside\nthe class scope since multiprocessing does not support parallelization with\nfunction internal to classes.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">star</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span>,</span><span class=\"param\">\t<span class=\"n\">approx_levels</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Set</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">Star</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.RefinementState", "modulename": "pynever.strategies.abstraction", "qualname": "RefinementState", "kind": "class", "doc": "<p>A class used for the internal control of the refinement strategies/heuristics applied in the abstraction refinement\nstep. At present is not still used and it is just an abstract placeholder. It will be used in future\nimplementations.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.abstraction.AbsLayerNode", "modulename": "pynever.strategies.abstraction", "qualname": "AbsLayerNode", "kind": "class", "doc": "<p>An abstract class used for our internal representation of a generic Abstract Transformer Layer of an\nAbsNeural Network. Its concrete children correspond to real abstract interpretation network layers.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier of the AbsLayerNode.</p>\n\n<p>ref_node : SingleInputLayerNode\n    Reference SingleInputLayerNode for the abstract transformer.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>forward(AbsElement)\n    Function which takes an AbsElement and compute the corresponding output AbsElement based on the abstract\n    transformer.</p>\n\n<p>backward(RefinementState)\n    Function which takes a reference to the refinement state and update both it and the state of the abstract\n    transformer to control the refinement component of the abstraction. At present the function is just a\n    placeholder for future implementations.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.abstraction.AbsLayerNode.identifier", "modulename": "pynever.strategies.abstraction", "qualname": "AbsLayerNode.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsLayerNode.ref_node", "modulename": "pynever.strategies.abstraction", "qualname": "AbsLayerNode.ref_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsLayerNode.forward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsLayerNode.forward", "kind": "function", "doc": "<p>Compute the output AbsElement based on the input AbsElement and the characteristics of the\nconcrete abstract transformer.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>abs_input : AbsElement\n    The input abstract element.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>AbsElement\n    The AbsElement resulting from the computation corresponding to the abstract transformer.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">abs_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsLayerNode.backward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsLayerNode.backward", "kind": "function", "doc": "<p>Update the RefinementState. At present the function is just a placeholder for future implementations.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>ref_state: RefinementState\n    The RefinementState to update.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ref_state</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">RefinementState</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsFullyConnectedNode", "modulename": "pynever.strategies.abstraction", "qualname": "AbsFullyConnectedNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Fully Connected Abstract transformer.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier of the SingleInputLayerNode.</p>\n\n<p>ref_node : FullyConnectedNode\n    SingleInputLayerNode di riferimento per l'abstract transformer.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>forward(AbsElement)\n    Function which takes an AbsElement and compute the corresponding output AbsElement based on the abstract\n    transformer.</p>\n\n<p>backward(RefinementState)\n    Function which takes a reference to the refinement state and update both it and the state of the abstract\n    transformer to control the refinement component of the abstraction. At present the function is just a\n    placeholder for future implementations.</p>\n", "bases": "AbsLayerNode"}, {"fullname": "pynever.strategies.abstraction.AbsFullyConnectedNode.__init__", "modulename": "pynever.strategies.abstraction", "qualname": "AbsFullyConnectedNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">ref_node</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">FullyConnectedNode</span></span>)</span>"}, {"fullname": "pynever.strategies.abstraction.AbsFullyConnectedNode.forward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsFullyConnectedNode.forward", "kind": "function", "doc": "<p>Compute the output AbsElement based on the input AbsElement and the characteristics of the\nconcrete abstract transformer.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>abs_input : AbsElement\n    The input abstract element.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>AbsElement\n    The AbsElement resulting from the computation corresponding to the abstract transformer.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">abs_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsFullyConnectedNode.backward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsFullyConnectedNode.backward", "kind": "function", "doc": "<p>Update the RefinementState. At present the function is just a placeholder for future implementations.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>ref_state: RefinementState\n    The RefinementState to update.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ref_state</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">RefinementState</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsReLUNode", "modulename": "pynever.strategies.abstraction", "qualname": "AbsReLUNode", "kind": "class", "doc": "<p>A class used for our internal representation of a ReLU Abstract transformer.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier of the SingleInputLayerNode.</p>\n\n<p>ref_node : ReLUNode\n    Reference SingleInputLayerNode for the abstract transformer.</p>\n\n<p>heuristic : str\n    Heuristic used to decide the refinement level of the abstraction.\n    At present can be only one of the following:\n    - complete: for each star all the neurons are processed with a precise abstraction\n    - mixed: for each star a given number of neurons is processed with a precise abstraction\n    - overapprox: for each star all the neurons are processed with a coarse abstraction</p>\n\n<p>params : List\n    Parameters for the heuristic of interest.\n    It is a List with the number of neurons to process with a precise abstraction in this layer.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>forward(AbsElement)\n    Function which takes an AbsElement and compute the corresponding output AbsElement based on the abstract\n    transformer.</p>\n\n<p>backward(RefinementState)\n    Function which takes a reference to the refinement state and update both it and the state of the abstract\n    transformer to control the refinement component of the abstraction. At present the function is just a\n    placeholder for future implementations.</p>\n", "bases": "AbsLayerNode"}, {"fullname": "pynever.strategies.abstraction.AbsReLUNode.__init__", "modulename": "pynever.strategies.abstraction", "qualname": "AbsReLUNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">ref_node</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">ReLUNode</span>,</span><span class=\"param\">\t<span class=\"n\">heuristic</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">params</span><span class=\"p\">:</span> <span class=\"n\">List</span></span>)</span>"}, {"fullname": "pynever.strategies.abstraction.AbsReLUNode.heuristic", "modulename": "pynever.strategies.abstraction", "qualname": "AbsReLUNode.heuristic", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsReLUNode.params", "modulename": "pynever.strategies.abstraction", "qualname": "AbsReLUNode.params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsReLUNode.layer_bounds", "modulename": "pynever.strategies.abstraction", "qualname": "AbsReLUNode.layer_bounds", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsReLUNode.n_areas", "modulename": "pynever.strategies.abstraction", "qualname": "AbsReLUNode.n_areas", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsReLUNode.forward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsReLUNode.forward", "kind": "function", "doc": "<p>Compute the output AbsElement based on the input AbsElement and the characteristics of the\nconcrete abstract transformer.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>abs_input : AbsElement\n    The input abstract element.</p>\n\n<p>bounds : dict\n    Optional bounds for this layer as computed by the previous</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>AbsElement\n    The AbsElement resulting from the computation corresponding to the abstract transformer.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">abs_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span>,</span><span class=\"param\">\t<span class=\"n\">bounds</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">bounds</span><span class=\"o\">.</span><span class=\"n\">AbstractBounds</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsReLUNode.backward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsReLUNode.backward", "kind": "function", "doc": "<p>Update the RefinementState. At present the function is just a placeholder for future implementations.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>ref_state: RefinementState\n    The RefinementState to update.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ref_state</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">RefinementState</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsSigmoidNode", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSigmoidNode", "kind": "class", "doc": "<p>A class used for our internal representation of a Sigmoid transformer.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier of the SingleInputLayerNode.</p>\n\n<p>ref_node : SigmoidNode\n    SingleInputLayerNode di riferimento per l'abstract transformer.</p>\n\n<p>refinement_level : Union[int, List[int]]\n    Refinement level for the sigmoid nodes: if it is a single int then that refinement level is applied to all\n    the neurons of the layers, otherwise it is a list containing the refinement levels for each layers.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>forward(AbsElement)\n    Function which takes an AbsElement and compute the corresponding output AbsElement based on the abstract\n    transformer.</p>\n\n<p>backward(RefinementState)\n    Function which takes a reference to the refinement state and update both it and the state of the abstract\n    transformer to control the refinement component of the abstraction. At present the function is just a\n    placeholder for future implementations.</p>\n", "bases": "AbsLayerNode"}, {"fullname": "pynever.strategies.abstraction.AbsSigmoidNode.__init__", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSigmoidNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">ref_node</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">nodes</span><span class=\"o\">.</span><span class=\"n\">SigmoidNode</span>,</span><span class=\"param\">\t<span class=\"n\">approx_levels</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.strategies.abstraction.AbsSigmoidNode.approx_levels", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSigmoidNode.approx_levels", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsSigmoidNode.forward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSigmoidNode.forward", "kind": "function", "doc": "<p>Compute the output AbsElement based on the input AbsElement and the characteristics of the\nconcrete abstract transformer.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>abs_input : AbsElement\n    The input abstract element.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>AbsElement\n    The AbsElement resulting from the computation corresponding to the abstract transformer.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">abs_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsSigmoidNode.backward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSigmoidNode.backward", "kind": "function", "doc": "<p>Update the RefinementState. At present the function is just a placeholder for future implementations.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>ref_state: RefinementState\n    The RefinementState to update.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ref_state</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">RefinementState</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsNeuralNetwork", "modulename": "pynever.strategies.abstraction", "qualname": "AbsNeuralNetwork", "kind": "class", "doc": "<p>An abstract class used for our internal representation of a generic NeuralNetwork for Abstract Interpretation.\nIt consists of a graph of AbsLayerNodes. The properties of the computational graph are specialized in the\nconcrete classes. The method forward and backward calls the corresponding methods in the AbsLayerNodes following the\ncorrect order to compute the output AbsElement.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>nodes : dict <str, SingleInputLayerNode>\n    Dictionary containing str keys and AbsLayerNodes values. It contains the nodes of the graph,\n    the identifier of the node of interest is used as a key in the nodes dictionary.</p>\n\n<p>edges : dict <str, list <str>&gt;\n    Dictionary of identifiers of AbsLayerNodes, it contains for each nodes identified by the keys, the list of nodes\n    connected to it.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>forward(AbsElement)\n    Function which takes an AbsElement and compute the corresponding output AbsElement based on the AbsLayerNode\n    of the network.</p>\n\n<p>backward(RefinementState)\n    Function which takes a reference to the refinement state and update both it and the state of the AbsLayerNodes\n    to control the refinement component of the abstraction. At present the function is just a placeholder\n    for future implementations.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.abstraction.AbsNeuralNetwork.nodes", "modulename": "pynever.strategies.abstraction", "qualname": "AbsNeuralNetwork.nodes", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsNeuralNetwork.edges", "modulename": "pynever.strategies.abstraction", "qualname": "AbsNeuralNetwork.edges", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsNeuralNetwork.forward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsNeuralNetwork.forward", "kind": "function", "doc": "<p>Compute the output AbsElement based on the input AbsElement and the characteristics of the\nconcrete abstract transformers.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>abs_input : AbsElement\n    The input abstract element.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>AbsElement\n    The AbsElement resulting from the computation corresponding to the abstract transformer.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">abs_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsNeuralNetwork.backward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsNeuralNetwork.backward", "kind": "function", "doc": "<p>Update the RefinementState. At present the function is just a placeholder for future implementations.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>ref_state: RefinementState\n    The RefinementState to update.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ref_state</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">RefinementState</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork", "kind": "class", "doc": "<p>Concrete children of AbsNeuralNetwork representing a sequential AbsNeuralNetwork.\nIt consists of a graph of LayerNodes. The computational graph of a SequentialNetwork must\ncorrespond to a standard list. The method forward and backward calls the corresponding methods\nin the AbsLayerNodes following the correct order to compute the output AbsElement.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    Identifier of the Sequential AbsNeuralNetwork.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>add_node(SingleInputLayerNode)\n    Procedure to add a new AbsLayerNode to the sequential AbsNeuralNetwork.</p>\n\n<p>get_first_node()\n    Procedure to extract the first AbsLayerNode of the sequential AbsNeuralNetwork.</p>\n\n<p>get_next_node(SingleInputLayerNode)\n    Procedure to get the next AbsLayerNode of the AbsNeuralNetwork given an input AbsLayerNode</p>\n\n<p>get_last_node()\n    Procedure to extract the last AbsLayerNode of the sequential AbsNeuralNetwork.</p>\n\n<p>forward(AbsElement)\n    Function which takes an AbsElement and compute the corresponding output AbsElement based on the AbsLayerNode\n    of the network.</p>\n\n<p>backward(RefinementState)\n    Function which takes a reference to the refinement state and update both it and the state of the AbsLayerNodes\n    to control the refinement component of the abstraction. At present the function is just a placeholder for\n    future implementations.</p>\n", "bases": "AbsNeuralNetwork"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork.__init__", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork.identifier", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork.add_node", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork.add_node", "kind": "function", "doc": "<p>Procedure to add a new AbsLayerNode. In sequential network the new node must be connected directly to the\nprevious node forming a list.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>node : AbsLayerNode\n    New node to add to the Sequential network.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">node</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsLayerNode</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork.get_first_node", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork.get_first_node", "kind": "function", "doc": "<p>Procedure to get the first AbsLayerNode of the network.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>AbsLayerNode\n    The first node of the network.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsLayerNode</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork.get_next_node", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork.get_next_node", "kind": "function", "doc": "<p>Procedure to get the next AbsLayerNode of the network given an input AbsLayerNode.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>SingleInputLayerNode\n    The next node of the network.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">node</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsLayerNode</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsLayerNode</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork.get_last_node", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork.get_last_node", "kind": "function", "doc": "<p>Procedure to get the last AbsLayerNode of the network.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>AbsLayerNode\n    The last node of the network.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsLayerNode</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork.forward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork.forward", "kind": "function", "doc": "<p>Compute the output AbsElement based on the input AbsElement and the characteristics of the\nconcrete abstract transformers.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>abs_input : AbsElement\n    The input abstract element.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>AbsElement\n    The AbsElement resulting from the computation corresponding to the abstract transformer.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">abs_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">AbsElement</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.abstraction.AbsSeqNetwork.backward", "modulename": "pynever.strategies.abstraction", "qualname": "AbsSeqNetwork.backward", "kind": "function", "doc": "<p>Update the RefinementState. At present the function is just a placeholder for future implementations.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>ref_state: RefinementState\n    The RefinementState to update.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ref_state</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">RefinementState</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp", "modulename": "pynever.strategies.bp", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds", "modulename": "pynever.strategies.bp.bounds", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds.AbstractBounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "AbstractBounds", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds.AbstractBounds.__init__", "modulename": "pynever.strategies.bp.bounds", "qualname": "AbstractBounds.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lower</span>, </span><span class=\"param\"><span class=\"n\">upper</span></span>)</span>"}, {"fullname": "pynever.strategies.bp.bounds.AbstractBounds.lower", "modulename": "pynever.strategies.bp.bounds", "qualname": "AbstractBounds.lower", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds.AbstractBounds.upper", "modulename": "pynever.strategies.bp.bounds", "qualname": "AbstractBounds.upper", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds.AbstractBounds.get_lower", "modulename": "pynever.strategies.bp.bounds", "qualname": "AbstractBounds.get_lower", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.AbstractBounds.get_upper", "modulename": "pynever.strategies.bp.bounds", "qualname": "AbstractBounds.get_upper", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.HyperRectangleBounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "HyperRectangleBounds", "kind": "class", "doc": "<p></p>\n", "bases": "AbstractBounds"}, {"fullname": "pynever.strategies.bp.bounds.HyperRectangleBounds.__init__", "modulename": "pynever.strategies.bp.bounds", "qualname": "HyperRectangleBounds.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lower</span>, </span><span class=\"param\"><span class=\"n\">upper</span></span>)</span>"}, {"fullname": "pynever.strategies.bp.bounds.HyperRectangleBounds.size", "modulename": "pynever.strategies.bp.bounds", "qualname": "HyperRectangleBounds.size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds.HyperRectangleBounds.get_size", "modulename": "pynever.strategies.bp.bounds", "qualname": "HyperRectangleBounds.get_size", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.HyperRectangleBounds.get_upper_bounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "HyperRectangleBounds.get_upper_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.HyperRectangleBounds.get_lower_bounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "HyperRectangleBounds.get_lower_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.HyperRectangleBounds.get_dimension_bounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "HyperRectangleBounds.get_dimension_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">dim</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.SymbolicLinearBounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "SymbolicLinearBounds", "kind": "class", "doc": "<p></p>\n", "bases": "AbstractBounds"}, {"fullname": "pynever.strategies.bp.bounds.SymbolicLinearBounds.__init__", "modulename": "pynever.strategies.bp.bounds", "qualname": "SymbolicLinearBounds.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lower</span>, </span><span class=\"param\"><span class=\"n\">upper</span></span>)</span>"}, {"fullname": "pynever.strategies.bp.bounds.SymbolicLinearBounds.size", "modulename": "pynever.strategies.bp.bounds", "qualname": "SymbolicLinearBounds.size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds.SymbolicLinearBounds.get_size", "modulename": "pynever.strategies.bp.bounds", "qualname": "SymbolicLinearBounds.get_size", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.SymbolicLinearBounds.get_upper_bounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "SymbolicLinearBounds.get_upper_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.SymbolicLinearBounds.get_lower_bounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "SymbolicLinearBounds.get_lower_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.SymbolicLinearBounds.get_all_bounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "SymbolicLinearBounds.get_all_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds.SymbolicLinearBounds.to_hyper_rectangle_bounds", "modulename": "pynever.strategies.bp.bounds", "qualname": "SymbolicLinearBounds.to_hyper_rectangle_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager", "modulename": "pynever.strategies.bp.bounds_manager", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager.__init__", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">abst_net</span>, </span><span class=\"param\"><span class=\"n\">prop</span></span>)</span>"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager.numeric_bounds", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager.numeric_bounds", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager.abst_net", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager.abst_net", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager.prop", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager.prop", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager.compute_bounds", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager.compute_bounds", "kind": "function", "doc": "<p>precomputes bounds for all nodes using symbolic linear propagation</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager.compute_dense_output_bounds", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager.compute_dense_output_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">layer</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager.compute_relu_output_bounds", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager.compute_relu_output_bounds", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span>, </span><span class=\"param\"><span class=\"n\">input_hyper_rect</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.BoundsManager.compute_symb_lin_bounds_equations", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "BoundsManager.compute_symb_lin_bounds_equations", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span>, </span><span class=\"param\"><span class=\"n\">lower_l</span>, </span><span class=\"param\"><span class=\"n\">lower_u</span>, </span><span class=\"param\"><span class=\"n\">upper_l</span>, </span><span class=\"param\"><span class=\"n\">upper_u</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.get_transformed_matrix", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "get_transformed_matrix", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">matrix</span>, </span><span class=\"param\"><span class=\"n\">k</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.get_transformed_offset", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "get_transformed_offset", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">offset</span>, </span><span class=\"param\"><span class=\"n\">k</span>, </span><span class=\"param\"><span class=\"n\">b</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.get_array_lin_lower_bound_coefficients", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "get_array_lin_lower_bound_coefficients", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lower</span>, </span><span class=\"param\"><span class=\"n\">upper</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.get_array_lin_upper_bound_coefficients", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "get_array_lin_upper_bound_coefficients", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lower</span>, </span><span class=\"param\"><span class=\"n\">upper</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.get_lin_lower_bound_coefficients", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "get_lin_lower_bound_coefficients", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lower</span>, </span><span class=\"param\"><span class=\"n\">upper</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.get_lin_upper_bound_coefficients", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "get_lin_upper_bound_coefficients", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lower</span>, </span><span class=\"param\"><span class=\"n\">upper</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.bounds_manager.get_abstract_network", "modulename": "pynever.strategies.bp.bounds_manager", "qualname": "get_abstract_network", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">abst_network</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions", "modulename": "pynever.strategies.bp.linearfunctions", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions", "kind": "class", "doc": "<p>matrix is an (n x m) np array\noffset is an (n) np array</p>\n\n<p>An object represents n linear functions f(i) of m input variables x</p>\n\n<p>f(i) = matrix[i]*x + offset[i]</p>\n"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.__init__", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">matrix</span>, </span><span class=\"param\"><span class=\"n\">offset</span></span>)</span>"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.size", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.matrix", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.matrix", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.offset", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.offset", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.clone", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.clone", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.get_size", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.get_size", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.get_matrix", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.get_matrix", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.get_offset", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.get_offset", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.compute_value", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.compute_value", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">row_number</span>, </span><span class=\"param\"><span class=\"n\">input_values</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.compute_values", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.compute_values", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_values</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.compute_max_value", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.compute_max_value", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">row_number</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.compute_min_value", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.compute_min_value", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">row_number</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.compute_max_values", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.compute_max_values", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.compute_min_values", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.compute_min_values", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.get_input_for_max", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.get_input_for_max", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.linearfunctions.LinearFunctions.get_input_for_min", "modulename": "pynever.strategies.bp.linearfunctions", "qualname": "LinearFunctions.get_input_for_min", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_bounds</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.utils", "modulename": "pynever.strategies.bp.utils", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.utils.property_converter", "modulename": "pynever.strategies.bp.utils.property_converter", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.utils.property_converter.DEBUG", "modulename": "pynever.strategies.bp.utils.property_converter", "qualname": "DEBUG", "kind": "variable", "doc": "<p></p>\n", "default_value": "False"}, {"fullname": "pynever.strategies.bp.utils.property_converter.PropertyFormatConverter", "modulename": "pynever.strategies.bp.utils.property_converter", "qualname": "PropertyFormatConverter", "kind": "class", "doc": "<p>A class used for converting a NeverProperty in format Cx&lt;=d into two vectors: a lower_bound_vector and an\nupper_bound_vector.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>coeff : Tensor\n    The representation of matrix C\nbias : Tensor\n    The representation of vector d</p>\n"}, {"fullname": "pynever.strategies.bp.utils.property_converter.PropertyFormatConverter.__init__", "modulename": "pynever.strategies.bp.utils.property_converter", "qualname": "PropertyFormatConverter.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"nb\">property</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.strategies.bp.utils.property_converter.PropertyFormatConverter.num_vars", "modulename": "pynever.strategies.bp.utils.property_converter", "qualname": "PropertyFormatConverter.num_vars", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.utils.property_converter.PropertyFormatConverter.lower_bound_vector", "modulename": "pynever.strategies.bp.utils.property_converter", "qualname": "PropertyFormatConverter.lower_bound_vector", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.utils.property_converter.PropertyFormatConverter.upper_bound_vector", "modulename": "pynever.strategies.bp.utils.property_converter", "qualname": "PropertyFormatConverter.upper_bound_vector", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.utils.property_converter.PropertyFormatConverter.check_input_validity", "modulename": "pynever.strategies.bp.utils.property_converter", "qualname": "PropertyFormatConverter.check_input_validity", "kind": "function", "doc": "<p>This code checks if every input variable has its own lower and upper value set, otherwise il closes the program</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.utils.property_converter.PropertyFormatConverter.get_vectors", "modulename": "pynever.strategies.bp.utils.property_converter", "qualname": "PropertyFormatConverter.get_vectors", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">bounds</span><span class=\"o\">.</span><span class=\"n\">HyperRectangleBounds</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.utils.utils", "modulename": "pynever.strategies.bp.utils.utils", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.bp.utils.utils.get_positive_part", "modulename": "pynever.strategies.bp.utils.utils", "qualname": "get_positive_part", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">weights</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.utils.utils.get_negative_part", "modulename": "pynever.strategies.bp.utils.utils", "qualname": "get_negative_part", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">weights</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.utils.utils.compute_lower", "modulename": "pynever.strategies.bp.utils.utils", "qualname": "compute_lower", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">weights_minus</span>, </span><span class=\"param\"><span class=\"n\">weights_plus</span>, </span><span class=\"param\"><span class=\"n\">input_lower</span>, </span><span class=\"param\"><span class=\"n\">input_upper</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.utils.utils.compute_upper", "modulename": "pynever.strategies.bp.utils.utils", "qualname": "compute_upper", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">weights_minus</span>, </span><span class=\"param\"><span class=\"n\">weights_plus</span>, </span><span class=\"param\"><span class=\"n\">input_lower</span>, </span><span class=\"param\"><span class=\"n\">input_upper</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.bp.utils.utils.compute_lin_lower_and_upper", "modulename": "pynever.strategies.bp.utils.utils", "qualname": "compute_lin_lower_and_upper", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">weights_minus</span>,</span><span class=\"param\">\t<span class=\"n\">weights_plus</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span>,</span><span class=\"param\">\t<span class=\"n\">lower_matrix</span>,</span><span class=\"param\">\t<span class=\"n\">upper_matrix</span>,</span><span class=\"param\">\t<span class=\"n\">lower_offset</span>,</span><span class=\"param\">\t<span class=\"n\">upper_offset</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.conversion", "modulename": "pynever.strategies.conversion", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.conversion.AlternativeRepresentation", "modulename": "pynever.strategies.conversion", "qualname": "AlternativeRepresentation", "kind": "class", "doc": "<p>An abstract class used to represent an alternative representation for a neural network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>identifier : str\n    identifier for the alternative representation\nup_to_date : bool, optional\n    flag which indicates if the alternative representation is up-to-date with respect\n    to the internal representation of the network (optional: True).</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.conversion.AlternativeRepresentation.__init__", "modulename": "pynever.strategies.conversion", "qualname": "AlternativeRepresentation.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">up_to_date</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.strategies.conversion.AlternativeRepresentation.identifier", "modulename": "pynever.strategies.conversion", "qualname": "AlternativeRepresentation.identifier", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.conversion.AlternativeRepresentation.up_to_date", "modulename": "pynever.strategies.conversion", "qualname": "AlternativeRepresentation.up_to_date", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.conversion.ONNXNetwork", "modulename": "pynever.strategies.conversion", "qualname": "ONNXNetwork", "kind": "class", "doc": "<p>A class used to represent a ONNX representation for a neural network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>onnx_network : onnx.ModelProto\n    Real ONNX network.</p>\n", "bases": "AlternativeRepresentation"}, {"fullname": "pynever.strategies.conversion.ONNXNetwork.__init__", "modulename": "pynever.strategies.conversion", "qualname": "ONNXNetwork.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">onnx_network</span><span class=\"p\">:</span> <span class=\"n\">onnx</span><span class=\"o\">.</span><span class=\"n\">onnx_ml_pb2</span><span class=\"o\">.</span><span class=\"n\">ModelProto</span>,</span><span class=\"param\">\t<span class=\"n\">up_to_date</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.strategies.conversion.ONNXNetwork.onnx_network", "modulename": "pynever.strategies.conversion", "qualname": "ONNXNetwork.onnx_network", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.conversion.PyTorchNetwork", "modulename": "pynever.strategies.conversion", "qualname": "PyTorchNetwork", "kind": "class", "doc": "<p>A class used to represent a PyTorch representation for a neural network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<pre><code>identifier for the alternative representation\n</code></pre>\n\n<p>pytorch_network : torch.nn.Module\n    Real PyTorch network.</p>\n", "bases": "AlternativeRepresentation"}, {"fullname": "pynever.strategies.conversion.PyTorchNetwork.__init__", "modulename": "pynever.strategies.conversion", "qualname": "PyTorchNetwork.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">identifier</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">pytorch_network</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">up_to_date</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.strategies.conversion.PyTorchNetwork.pytorch_network", "modulename": "pynever.strategies.conversion", "qualname": "PyTorchNetwork.pytorch_network", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.conversion.ConversionStrategy", "modulename": "pynever.strategies.conversion", "qualname": "ConversionStrategy", "kind": "class", "doc": "<p>An abstract class used to represent a Conversion Strategy.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>from_neural_network(NeuralNetwork)\n    Convert the neural network of interest to an alternative representation determined in the concrete children.\nto_neural_network(AlternativeRepresentation)\n    Convert the alternative representation of interest to our internal representation of a Neural Network.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.conversion.ConversionStrategy.from_neural_network", "modulename": "pynever.strategies.conversion", "qualname": "ConversionStrategy.from_neural_network", "kind": "function", "doc": "<p>Convert the neural network of interest to an alternative representation determined in the concrete children.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to convert.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>AlternativeRepresentation\n    The alternative representation resulting from the conversion of the original network.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">AlternativeRepresentation</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.conversion.ConversionStrategy.to_neural_network", "modulename": "pynever.strategies.conversion", "qualname": "ConversionStrategy.to_neural_network", "kind": "function", "doc": "<p>Convert the alternative representation of interest to the internal one.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>alt_rep : AlternativeRepresentation\n    The Alternative Representation to convert.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeuralNetwork\n    The Neural Network resulting from the conversion of Alternative Representation.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">alt_rep</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">AlternativeRepresentation</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.conversion.ONNXConverter", "modulename": "pynever.strategies.conversion", "qualname": "ONNXConverter", "kind": "class", "doc": "<p>A class used to represent the conversion strategy for ONNX models.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>from_neural_network(NeuralNetwork)\n    Convert the neural network of interest to a ONNXNetwork model.\nto_neural_network(ONNXNetwork)\n    Convert the ONNXNetwork of interest to our internal representation of a Neural Network.</p>\n", "bases": "ConversionStrategy"}, {"fullname": "pynever.strategies.conversion.ONNXConverter.from_neural_network", "modulename": "pynever.strategies.conversion", "qualname": "ONNXConverter.from_neural_network", "kind": "function", "doc": "<p>Convert the neural network of interest to a ONNX representation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to convert.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>ONNXNetwork\n    The ONNX representation resulting from the conversion of the original network.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ONNXNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.conversion.ONNXConverter.to_neural_network", "modulename": "pynever.strategies.conversion", "qualname": "ONNXConverter.to_neural_network", "kind": "function", "doc": "<p>Convert the ONNX representation of interest to the internal one.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>alt_rep : ONNXNetwork\n    The ONNX Representation to convert.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeuralNetwork\n    The Neural Network resulting from the conversion of ONNX Representation.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">alt_rep</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ONNXNetwork</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.conversion.PyTorchConverter", "modulename": "pynever.strategies.conversion", "qualname": "PyTorchConverter", "kind": "class", "doc": "<p>A class used to represent the conversion strategy for PyTorch models.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>from_neural_network(NeuralNetwork)\n    Convert the neural network of interest to a PyTorchNetwork model.\nto_neural_network(PyTorchNetwork)\n    Convert the PyTorchNetwork of interest to our internal representation of a Neural Network.</p>\n", "bases": "ConversionStrategy"}, {"fullname": "pynever.strategies.conversion.PyTorchConverter.from_neural_network", "modulename": "pynever.strategies.conversion", "qualname": "PyTorchConverter.from_neural_network", "kind": "function", "doc": "<p>Convert the neural network of interest to a PyTorch representation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to convert.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>PyTorchNetwork\n    The PyTorch representation resulting from the conversion of the original network.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">PyTorchNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.conversion.PyTorchConverter.to_neural_network", "modulename": "pynever.strategies.conversion", "qualname": "PyTorchConverter.to_neural_network", "kind": "function", "doc": "<p>Convert the PyTorch representation of interest to the internal one.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>alt_rep : PyTorchNetwork\n    The PyTorch Representation to convert.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeuralNetwork\n    The Neural Network resulting from the conversion of PyTorch Representation.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">alt_rep</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">PyTorchNetwork</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.conversion.load_network_path", "modulename": "pynever.strategies.conversion", "qualname": "load_network_path", "kind": "function", "doc": "<p>Method to load a network from a path in an Alternative Representation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>path : str\n    Path to the network.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>Optional[AlternativeRepresentation]\n    The AlternativeRepresentation object if the network is supported, None otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">AlternativeRepresentation</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.conversion.save_network_path", "modulename": "pynever.strategies.conversion", "qualname": "save_network_path", "kind": "function", "doc": "<p>Method to save a network to file from an AlternativeRepresentation</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : AlternativeRepresentation\n    The network to save.\npath : str\n    Path to save the network.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">AlternativeRepresentation</span>,</span><span class=\"param\">\t<span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.pruning", "modulename": "pynever.strategies.pruning", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.PruningStrategy", "modulename": "pynever.strategies.pruning", "qualname": "PruningStrategy", "kind": "class", "doc": "<p>An abstract class used to represent a Pruning Strategy.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>prune(NeuralNetwork, Dataset)\n    Prune the neural network of interest using a pruning strategy determined in the concrete children.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.pruning.PruningStrategy.prune", "modulename": "pynever.strategies.pruning", "qualname": "PruningStrategy.prune", "kind": "function", "doc": "<p>Prune the neural network of interest using a pruning strategy determined in the concrete children.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to prune.\ndataset: Dataset\n    The dataset to use for the pre-training and fine-tuning procedure.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeuralNetwork\n    The Neural Network resulting from the application of the pruning strategy to the original network.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.pruning.WPTransform", "modulename": "pynever.strategies.pruning", "qualname": "WPTransform", "kind": "class", "doc": "<p>Callable to pass to the training strategy used in the pruning in order to optimize it for the pruning.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>l1_decay : float\n    Coefficient of the L1 norm regularizer used on the weights of the linear layers of the network\n    to push the weights to near-to-zero values.\nfine_tuning : bool\n    If True the weight with value zero are not updated by the optimizer step, otherwise the L1 regularizer\n    is used.\ncuda : bool, Optional\n    It should be the same of the training strategy receiving the callable as network transform</p>\n"}, {"fullname": "pynever.strategies.pruning.WPTransform.__init__", "modulename": "pynever.strategies.pruning", "qualname": "WPTransform.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">l1_decay</span><span class=\"p\">:</span> <span class=\"nb\">float</span>, </span><span class=\"param\"><span class=\"n\">fine_tuning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>, </span><span class=\"param\"><span class=\"n\">cuda</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "pynever.strategies.pruning.WPTransform.l1_decay", "modulename": "pynever.strategies.pruning", "qualname": "WPTransform.l1_decay", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.WPTransform.fine_tuning", "modulename": "pynever.strategies.pruning", "qualname": "WPTransform.fine_tuning", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.WPTransform.cuda", "modulename": "pynever.strategies.pruning", "qualname": "WPTransform.cuda", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.NSTransform", "modulename": "pynever.strategies.pruning", "qualname": "NSTransform", "kind": "class", "doc": "<p>Callable to pass to the training strategy used in the pruning in order to optimize it for the pruning.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>batchnorm_decay : float\n    Coefficient of the L1 norm regularizer used on the batchnorm layers of the network\n    to push the weights to near-to-zero values.\nfine_tuning : bool\n    If True the L1 regularizer is not applied to the network.\ncuda : bool, Optional\n    It should be the same of the training strategy receiving the callable as network transform</p>\n"}, {"fullname": "pynever.strategies.pruning.NSTransform.__init__", "modulename": "pynever.strategies.pruning", "qualname": "NSTransform.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">batchnorm_decay</span><span class=\"p\">:</span> <span class=\"nb\">float</span>, </span><span class=\"param\"><span class=\"n\">fine_tuning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>, </span><span class=\"param\"><span class=\"n\">cuda</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "pynever.strategies.pruning.NSTransform.batchnorm_decay", "modulename": "pynever.strategies.pruning", "qualname": "NSTransform.batchnorm_decay", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.NSTransform.fine_tuning", "modulename": "pynever.strategies.pruning", "qualname": "NSTransform.fine_tuning", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.NSTransform.cuda", "modulename": "pynever.strategies.pruning", "qualname": "NSTransform.cuda", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.WeightPruning", "modulename": "pynever.strategies.pruning", "qualname": "WeightPruning", "kind": "class", "doc": "<p>A concrete class used to represent the weight pruning strategy.\nThis kind of pruning select the least important weights of the neural network\nof interest and set them to 0. It assume vectorial input for the linear layers.\nWe refer to <a href=\"https://arxiv.org/abs/1506.02626\">https://arxiv.org/abs/1506.02626</a> for theoretical details on the strategy.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>sparsity_rate : float\n    It determines the percentage of neurons which will be removed. It must be a Real number between 0 and 1.\ntraining_strategy : PytorchTraining\n    The training strategy to use for pre-training and/or fine-tuning. NB: Its network_transform parameter must\n    be of the class WPTransform.\npre_training : bool\n    Flag to indicate if the network need to be pre-trained.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>prune(NeuralNetwork, Dataset)\n    Prune the neural network of interest using the pruning strategy Weight Pruning.</p>\n", "bases": "PruningStrategy"}, {"fullname": "pynever.strategies.pruning.WeightPruning.__init__", "modulename": "pynever.strategies.pruning", "qualname": "WeightPruning.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">sparsity_rate</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">training_strategy</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">PytorchTraining</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">pre_training</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "pynever.strategies.pruning.WeightPruning.sparsity_rate", "modulename": "pynever.strategies.pruning", "qualname": "WeightPruning.sparsity_rate", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.WeightPruning.training_strategy", "modulename": "pynever.strategies.pruning", "qualname": "WeightPruning.training_strategy", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.WeightPruning.pre_training", "modulename": "pynever.strategies.pruning", "qualname": "WeightPruning.pre_training", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.WeightPruning.prune", "modulename": "pynever.strategies.pruning", "qualname": "WeightPruning.prune", "kind": "function", "doc": "<p>Prune the neural network of interest using the pruning strategy Weight Pruning.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to prune.\ndataset : Dataset\n    The dataset to use for the pre-training and fine-tuning procedure.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeuralNetwork\n    The Neural Network resulting from the application of the pruning strategy to the original network.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.pruning.NetworkSlimming", "modulename": "pynever.strategies.pruning", "qualname": "NetworkSlimming", "kind": "class", "doc": "<p>A concrete class used to represent the network slimming pruning strategy.\nThis kind of pruning select the least important neurons of the neural network\nof interest and eliminates them. It needs a batch normalization layer following each layer\nwhich should be pruned. We assume that the activation function is always applied after the batch\nnormalization layer. It support only networks with linear and batchnorm layers with vectorial inputs\nWe refer to <a href=\"https://arxiv.org/abs/1708.06519\">https://arxiv.org/abs/1708.06519</a> for theoretical details on the strategy.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>sparsity_rate : float\n    It determines the percentage of neurons which will be removed. It must be a Real number between 0 and 1.\ntraining_strategy : PytorchTraining\n    The training strategy to use for pre-training and/or fine-tuning. NB: Its network_transform parameter must\n    be of the class NSTransform.\npre_training : bool\n    Flag to indicate if the network need to be pre-trained.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>prune(NeuralNetwork, Dataset)\n    Prune the neural network of interest using the pruning strategy Network Slimming.</p>\n", "bases": "PruningStrategy"}, {"fullname": "pynever.strategies.pruning.NetworkSlimming.__init__", "modulename": "pynever.strategies.pruning", "qualname": "NetworkSlimming.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">sparsity_rate</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">training_strategy</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">PytorchTraining</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">pre_training</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "pynever.strategies.pruning.NetworkSlimming.sparsity_rate", "modulename": "pynever.strategies.pruning", "qualname": "NetworkSlimming.sparsity_rate", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.NetworkSlimming.training_strategy", "modulename": "pynever.strategies.pruning", "qualname": "NetworkSlimming.training_strategy", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.NetworkSlimming.pre_training", "modulename": "pynever.strategies.pruning", "qualname": "NetworkSlimming.pre_training", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.pruning.NetworkSlimming.prune", "modulename": "pynever.strategies.pruning", "qualname": "NetworkSlimming.prune", "kind": "function", "doc": "<p>Prune the neural network of interest using the pruning strategy Network Slimming.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to prune.\ndataset: Dataset\n    The dataset to use for the pre-training and fine-tuning procedure.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeuralNetwork\n    The Neural Network resulting from the application of the pruning strategy to the original network.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading", "modulename": "pynever.strategies.smt_reading", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExprNode", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode", "kind": "class", "doc": "<p>Class representing a binary Expression Tree in form of a recursive node.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>data: str\n    This node content, may be a number or an algebraic operator.\nnode_left: ExprNode\n    The left sub-node, if empty this node is a leaf.\nnode_right: ExprNode\n    The right sub-node, if empty this node is a leaf.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>is_leaf()\n    Procedure to check whether the node is a leaf or not.\nas_prefix()\n    Procedure to create the prefix string describing the tree.\nas_infix()\n    Procedure to create the infix string describing the tree.\nget_disjunctions_infix()\n    Procedure to return the list of disjunct atoms, if present.</p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExprNode.__init__", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">char</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "pynever.strategies.smt_reading.ExprNode.data", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode.data", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExprNode.node_left", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode.node_left", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExprNode.node_right", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode.node_right", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExprNode.is_leaf", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode.is_leaf", "kind": "function", "doc": "<p>This method checks whether the node is a leaf or not.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True if node_left and node_right are None, False otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.ExprNode.as_prefix", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode.as_prefix", "kind": "function", "doc": "<p>This method converts the Expression Tree in a prefix string</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    The tree representation as a prefix string</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.ExprNode.as_infix", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode.as_infix", "kind": "function", "doc": "<p>This method converts the Expression Tree in an infix string</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    The tree representation as an infix string</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.ExprNode.get_disjunctions_infix", "modulename": "pynever.strategies.smt_reading", "qualname": "ExprNode.get_disjunctions_infix", "kind": "function", "doc": "<p>This method is used in order to separate OR statements in\nthe input file</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list\n    The list of infix-notated disjunctions</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">list</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.ExpressionTreeConverter", "modulename": "pynever.strategies.smt_reading", "qualname": "ExpressionTreeConverter", "kind": "class", "doc": "<p>Class for converting infix expressions to expression trees.</p>\n\n<p>Courtesy of Nikhil Kumar Singh(nickzuck_007) and aashish1995.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>precedence: dict\n    A dictionary assigning precedences to operators.\ncharStack: list\n    Stack for operands, needed in the conversion routine.\nnodeStack: list\n    Stack for operators, needed in the conversion routine.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>build_from_infix(str)\n    Procedure to generate an expression tree from an infix string.</p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExpressionTreeConverter.precedence", "modulename": "pynever.strategies.smt_reading", "qualname": "ExpressionTreeConverter.precedence", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExpressionTreeConverter.charStack", "modulename": "pynever.strategies.smt_reading", "qualname": "ExpressionTreeConverter.charStack", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExpressionTreeConverter.nodeStack", "modulename": "pynever.strategies.smt_reading", "qualname": "ExpressionTreeConverter.nodeStack", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.ExpressionTreeConverter.build_from_infix", "modulename": "pynever.strategies.smt_reading", "qualname": "ExpressionTreeConverter.build_from_infix", "kind": "function", "doc": "<p>This method builds an Expression Tree using the ExprNode class.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>infix: str\n    The infix-notated string to be converted.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>ExprNode\n    The root node containing the Expression Tree.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">infix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">smt_reading</span><span class=\"o\">.</span><span class=\"n\">ExprNode</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser", "kind": "class", "doc": "<p>SMTLIB parser utility for building a Star expressed in normal form:\nin_coef_mat * x &lt;= in_bias_mat\nout_coef_mat * y &lt;= out_bias_mat</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>smtlib_path: str\n    Path to the SMTLIB file in which the property is defined.\nx: list\n    Input vector.\ny: list\n    Output vector.\nx_name: str\n    Name of the input vector.\ny_name: str\n    Name of the output vector.\nin_coef_mat: Tensor\n    Matrix of the coefficients for the input constraints.\nin_bias_mat: Tensor\n    Matrix of the biases for the input constraints.\nout_coef_mat: list\n    List of matrices of the coefficients for the output constraints.\nout_bias_mat: list\n    List of matrices of the biases for the output constraints.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>__as_script()\n    Procedure to serialize the SMTLIB file as a list of commands via pysmt.\n__get_assert_commands_for(x)\n    Procedure to extract the SMTLIB 'assert' commands regarding the literal 'x'.\n__get_coef_mat(list, str, list)\n    Procedure to extract the input vector coefficients of the given Tensor\n    from the SMTLIB file.\n__get_bias_mat(list)\n    Procedure to extract the bias coefficients of the given Tensor from the\n    SMTLIB file.\nget_components_of(str)\n    Procedure to build a list containing the components of the 'str' vector,\n    i.e., the declared variables beginning with 'str' in the SMTLIB file.\nparse_property()\n    Exposed procedure to parse the SMTLIB file and build the NeVerProperty.</p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.__init__", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">smtlib_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">x_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">y_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.smtlib_path", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.smtlib_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.x_name", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.x_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.y_name", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.y_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.x", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.x", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.y", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.y", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.in_coef_mat", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.in_coef_mat", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.in_bias_mat", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.in_bias_mat", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.out_coef_mat", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.out_coef_mat", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.out_bias_mat", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.out_bias_mat", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.remove_parentheses", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.remove_parentheses", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cmd</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.get_components_of", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.get_components_of", "kind": "function", "doc": "<p>This method reads the components of the given named vector and\nreturns the corresponding list.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>vec_name: str\n    The vector name to find the components of.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list\n    A list containing the input vector components.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">vec_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">list</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.SmtPropertyParser.parse_property", "modulename": "pynever.strategies.smt_reading", "qualname": "SmtPropertyParser.parse_property", "kind": "function", "doc": "<p>This method exposes the propriety parsing, performing all the steps and\nfilling the Tensors.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeVerProperty\n    The parsed property wrapped in the corresponding class</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> (&lt;class &#x27;pynever.tensor.Tensor&#x27;&gt;, &lt;class &#x27;pynever.tensor.Tensor&#x27;&gt;, &lt;class &#x27;list&#x27;&gt;, &lt;class &#x27;list&#x27;&gt;):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.is_operator", "modulename": "pynever.strategies.smt_reading", "qualname": "is_operator", "kind": "function", "doc": "<p>Utility for checking operators.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>c: str\n    The character or string to check.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True if c is part of the operators set, False otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">c</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.read_smt_num", "modulename": "pynever.strategies.smt_reading", "qualname": "read_smt_num", "kind": "function", "doc": "<p>Procedure to convert a SMTLIB string to a number.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>val: str\n    A string containing a number from a SMT file.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>Any\n    int if the given string represents an integer,\n    float if it represents a float or\n    None if it does not represent a number.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">val</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.prefix2infix", "modulename": "pynever.strategies.smt_reading", "qualname": "prefix2infix", "kind": "function", "doc": "<p>Procedure for converting a prefix string to an infix string.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>prefix: str\n    The prefix string that should be converted.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    The infix-converted string.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">prefix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.smt_reading.refine_smt_statement", "modulename": "pynever.strategies.smt_reading", "qualname": "refine_smt_statement", "kind": "function", "doc": "<p>This method refines a SMTLIB statement by intercepting\nmalformed Normal Form formulas and rewriting them\ncorrectly.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>assertion\n    The SMT formula to verify.\nvec_name\n    The variable name in use</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    The formula in input if it is already well-formed,\n    its refinement otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">assertion</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">vec_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.training", "modulename": "pynever.strategies.training", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.logger_name", "modulename": "pynever.strategies.training", "qualname": "logger_name", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;pynever.strategies.training&#x27;"}, {"fullname": "pynever.strategies.training.TrainingStrategy", "modulename": "pynever.strategies.training", "qualname": "TrainingStrategy", "kind": "class", "doc": "<p>An abstract class used to represent a Training Strategy.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>train(NeuralNetwork, Dataset)\n    Train the neural network of interest using a training strategy determined in the concrete children.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.training.TrainingStrategy.train", "modulename": "pynever.strategies.training", "qualname": "TrainingStrategy.train", "kind": "function", "doc": "<p>Train the neural network of interest using a testing strategy determined in the concrete children.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to train.\ndataset : Dataset\n    The dataset to use to train the neural network.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeuralNetwork\n    The Neural Network resulting from the training of the original network using the training strategy and the\n    dataset.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.training.TestingStrategy", "modulename": "pynever.strategies.training", "qualname": "TestingStrategy", "kind": "class", "doc": "<p>An abstract class used to represent a Testing Strategy.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>test(NeuralNetwork, Dataset)\n    Test the neural network of interest using a testing strategy determined in the concrete children.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.training.TestingStrategy.test", "modulename": "pynever.strategies.training", "qualname": "TestingStrategy.test", "kind": "function", "doc": "<p>Test the neural network of interest using a testing strategy determined in the concrete children.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to test.\ndataset : Dataset\n    The dataset to use to test the neural network.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>float\n    A measure of the correctness of the networks dependant on the concrete children</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.training.PytorchTraining", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining", "kind": "class", "doc": "<p>Class used to represent the training strategy based on the Pytorch learning framework.\nIt supports different optimization algorithm, schedulers, loss function and others based on\nthe attributes provided at instantiation time.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>optimizer_con : type\n    Reference to the class constructor for the Optimizer of choice for the training strategy.</p>\n\n<p>opt_params : Dict\n    Dictionary of the parameters to pass to the constructor of the optimizer excluding the first which is always\n    assumed to be the parameters to optimize</p>\n\n<p>loss_function : Callable\n    Loss function for the training strategy. We assume it to take as parameters two pytorch Tensor\n    corresponding to the output of the network and the target. Other parameter should be given as attribute of\n    the callable object.</p>\n\n<p>n_epochs : int\n    Number of epochs for the training procedure.</p>\n\n<p>validation_percentage : float\n    Percentage of the dataset to use as the validation set</p>\n\n<p>train_batch_size : int\n    Dimension for the train batch size for the training procedure</p>\n\n<p>validation_batch_size : int\n    Dimension for the validation batch size for the training procedure</p>\n\n<p>scheduler_con : type, Optional\n    Reference to the class constructor for the Scheduler for the learning rate of choice for the training strategy\n    (default: None)</p>\n\n<p>sch_params : Dict, Optional\n    Dictionary of the parameters to pass to the constructor of the scheduler excluding the first which is always\n    assumed to be the optimizer whose learning rate must be updated. (default: None)</p>\n\n<p>precision_metric : Callable, Optional\n    Function for measuring the precision of the neural network. It is used to choose the best model and to control\n    the Plateau Scheduler and the early stopping. We assume it to take as parameters two pytorch Tensor\n    corresponding to the output of the network and the target.It should produce a float value and such value should\n    decrease for increasing correctness of the network (as the traditional loss value).\n    Optional supplementary parameters should be given as attributes of the object. (default: None)</p>\n\n<p>network_transform : Callable, Optional\n    We provide the possibility to define a function which will be applied to the network after\n    the computation of backward and before the optimizer step. In practice we use it for the manipulation\n    needed to the pruning oriented training. It should take a pytorch module (i.e., the neural network) as\n    input and optional supplementary parameters () should be given as attributes of the object. (default: None)</p>\n\n<p>cuda : bool, Optional\n    Whether to use the cuda library for the procedure (default: False).</p>\n\n<p>train_patience : int, Optional\n    The number of epochs in which the loss may not decrease before the\n    training procedure is interrupted with early stopping (default: None).</p>\n\n<p>checkpoints_root : str, Optional\n    Where to store the checkpoints of the training strategy. (default: '')</p>\n\n<p>verbose_rate : int, Optional\n    After how many batch the strategy prints information about how the training is going.</p>\n", "bases": "TrainingStrategy"}, {"fullname": "pynever.strategies.training.PytorchTraining.__init__", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">optimizer_con</span><span class=\"p\">:</span> <span class=\"nb\">type</span>,</span><span class=\"param\">\t<span class=\"n\">opt_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>,</span><span class=\"param\">\t<span class=\"n\">loss_function</span><span class=\"p\">:</span> <span class=\"n\">Callable</span>,</span><span class=\"param\">\t<span class=\"n\">n_epochs</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">validation_percentage</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">train_batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">validation_batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">r_split</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">scheduler_con</span><span class=\"p\">:</span> <span class=\"nb\">type</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">sch_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">precision_metric</span><span class=\"p\">:</span> <span class=\"n\">Callable</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">network_transform</span><span class=\"p\">:</span> <span class=\"n\">Callable</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">train_patience</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">checkpoints_root</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">verbose_rate</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.strategies.training.PytorchTraining.optimizer_con", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.optimizer_con", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.opt_params", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.opt_params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.scheduler_con", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.scheduler_con", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.sch_params", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.sch_params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.loss_function", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.loss_function", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.precision_metric", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.precision_metric", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.n_epochs", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.n_epochs", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.validation_percentage", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.validation_percentage", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.train_batch_size", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.train_batch_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.validation_batch_size", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.validation_batch_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.r_split", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.r_split", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.network_transform", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.network_transform", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.device", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.device", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.train_patience", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.train_patience", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.verbose_rate", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.verbose_rate", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.checkpoints_root", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.checkpoints_root", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTraining.train", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.train", "kind": "function", "doc": "<p>Train the neural network of interest using a testing strategy determined in the concrete children.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to train.\ndataset : Dataset\n    The dataset to use to train the neural network.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>NeuralNetwork\n    The Neural Network resulting from the training of the original network using the training strategy and the\n    dataset.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.training.PytorchTraining.pytorch_training", "modulename": "pynever.strategies.training", "qualname": "PytorchTraining.pytorch_training", "kind": "function", "doc": "<p>Training procedure for the PyTorchNetwork.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>net : PyTorchNetwork\n    The PyTorchNetwork to train.\ndataset : Dataset\n    The dataset to use for the training of the PyTorchNetwork</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>PyTorchNetwork\n    The trained PyTorchNetwork.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">net</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">PyTorchNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">PyTorchNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.training.PytorchTesting", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting", "kind": "class", "doc": "<p>Class used to represent the testing strategy based on the Pytorch learning framework.\nIt supports different metrics measure for the correctness of the neural network.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>metric : Callable\n    Function for measuring the precision/correctness of the neural network.</p>\n\n<p>metric_params : Dict\n    Supplementary parameters for the metric other than the output and the target (which should always be the first\n    two parameters of the metric. It is assumed that it produce a float value and such value\n    decrease for increasing correctness of the network (as the traditional loss value).</p>\n\n<p>test_batch_size : int\n    Dimension for the test batch size for the testing procedure</p>\n\n<p>cuda : bool, Optional\n    Whether to use the cuda library for the procedure (default: False).</p>\n\n<p>save_results : bool, Optional\n    Whether to save outputs, targets and losses as attributes.</p>\n", "bases": "TestingStrategy"}, {"fullname": "pynever.strategies.training.PytorchTesting.__init__", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">metric</span><span class=\"p\">:</span> <span class=\"n\">Callable</span>,</span><span class=\"param\">\t<span class=\"n\">metric_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>,</span><span class=\"param\">\t<span class=\"n\">test_batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">save_results</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">mps</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "pynever.strategies.training.PytorchTesting.metric", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.metric", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTesting.metric_params", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.metric_params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTesting.test_batch_size", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.test_batch_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTesting.device", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.device", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTesting.mps", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.mps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTesting.save_results", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.save_results", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchTesting.test", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.test", "kind": "function", "doc": "<p>Test the neural network of interest using a testing strategy determined in the concrete children.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to test.\ndataset : Dataset\n    The dataset to use to test the neural network.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>float\n    A measure of the correctness of the networks dependant on the concrete children</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.training.PytorchTesting.pytorch_testing", "modulename": "pynever.strategies.training", "qualname": "PytorchTesting.pytorch_testing", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">net</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">PyTorchNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">Dataset</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.training.PytorchMetrics", "modulename": "pynever.strategies.training", "qualname": "PytorchMetrics", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.training.PytorchMetrics.inaccuracy", "modulename": "pynever.strategies.training", "qualname": "PytorchMetrics.inaccuracy", "kind": "function", "doc": "<p>Function to compute the inaccuracy of a prediction. It assumes that the task is classification, the output is\na Tensor of shape (n, d) where d is the number of possible classes. The target is a Tensor of shape (n, 1) of\nint whose elements correspond to the correct class for the n-th sample. The index of the output element with\nthe greater value (considering the n-th Tensor) correspond to the class predicted. We consider the inaccuracy\nmetric instead than the accuracy because our metric functions must follow the rule: \"lower value equals to\nbetter network\" like the loss functions.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>output : torch.Tensor\n    Output predicted by the network. It should be a Tensor of shape (n, d)\ntarget : torch.Tensor\n    Correct class for the prediction. It should be a Tensor of shape (n, 1)</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>float\n    Number of correct prediction / number of sample analyzed</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">output</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">target</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.verification", "modulename": "pynever.strategies.verification", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.logger_name", "modulename": "pynever.strategies.verification", "qualname": "logger_name", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;pynever.strategies.verification&#x27;"}, {"fullname": "pynever.strategies.verification.Property", "modulename": "pynever.strategies.verification", "qualname": "Property", "kind": "class", "doc": "<p>An abstract class used to represent a generic property for a NeuralNetwork.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.verification.LocalRobustnessProperty", "modulename": "pynever.strategies.verification", "qualname": "LocalRobustnessProperty", "kind": "class", "doc": "<p>A concrete class used to represent a local robustness property for a NeuralNetwork.\nFormally the property check if the counterexample (i.e., the adversarial example) exists, therefore\nwhen the verification strategy check such property it should return True if the adversarial example exist and\nfalse otherwise.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>data : Tensor\n    Original data used to determine the local robustness.\ntarget : int\n    If targeted is True then it is the desired target for the adversarial, otherwise it is the correct target of\n    data.\ntargeted : bool\n    Flag which is True if the robustness property is targeted, False otherwise.\nnorm : str\n    Norm type used to determine the local robustness. At present the only acceptable value is Linf.\nepsilon : float\n    Magnitude of the acceptable perturbation.\nbounds: list\n    List of (lower_bound, upper_bound) for the data.</p>\n", "bases": "Property"}, {"fullname": "pynever.strategies.verification.LocalRobustnessProperty.__init__", "modulename": "pynever.strategies.verification", "qualname": "LocalRobustnessProperty.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">target</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">targeted</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">bounds</span><span class=\"p\">:</span> <span class=\"nb\">list</span></span>)</span>"}, {"fullname": "pynever.strategies.verification.LocalRobustnessProperty.data", "modulename": "pynever.strategies.verification", "qualname": "LocalRobustnessProperty.data", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.LocalRobustnessProperty.target", "modulename": "pynever.strategies.verification", "qualname": "LocalRobustnessProperty.target", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.LocalRobustnessProperty.targeted", "modulename": "pynever.strategies.verification", "qualname": "LocalRobustnessProperty.targeted", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.LocalRobustnessProperty.norm", "modulename": "pynever.strategies.verification", "qualname": "LocalRobustnessProperty.norm", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.LocalRobustnessProperty.epsilon", "modulename": "pynever.strategies.verification", "qualname": "LocalRobustnessProperty.epsilon", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.LocalRobustnessProperty.bounds", "modulename": "pynever.strategies.verification", "qualname": "LocalRobustnessProperty.bounds", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeVerProperty", "modulename": "pynever.strategies.verification", "qualname": "NeVerProperty", "kind": "class", "doc": "<p>A concrete class used to represent a NeVer property for a NeuralNetwork. We assume that the hyperplane\nout_coef_mat * y &lt;= out_bias_mat represent the unsafe region (i.e., the negation of the desired property).\nAt present the input set must be defined as in_coef_mat * x &lt;= in_bias_mat</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>in_coef_mat: Tensor\n    Matrix of the coefficients for the input constraints.\nin_bias_mat: Tensor\n    Matrix of the biases for the input constraints.\nout_coef_mat: List[Tensor]\n    Matrixes of the coefficients for the output constraints.\nout_bias_mat: List[Tensor]\n    Matrixes of the biases for the output constraints.</p>\n", "bases": "Property"}, {"fullname": "pynever.strategies.verification.NeVerProperty.__init__", "modulename": "pynever.strategies.verification", "qualname": "NeVerProperty.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_coef_mat</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">in_bias_mat</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">out_coef_mat</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">out_bias_mat</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.strategies.verification.NeVerProperty.in_coef_mat", "modulename": "pynever.strategies.verification", "qualname": "NeVerProperty.in_coef_mat", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeVerProperty.in_bias_mat", "modulename": "pynever.strategies.verification", "qualname": "NeVerProperty.in_bias_mat", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeVerProperty.out_coef_mat", "modulename": "pynever.strategies.verification", "qualname": "NeVerProperty.out_coef_mat", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeVerProperty.out_bias_mat", "modulename": "pynever.strategies.verification", "qualname": "NeVerProperty.out_bias_mat", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeVerProperty.from_smt_file", "modulename": "pynever.strategies.verification", "qualname": "NeVerProperty.from_smt_file", "kind": "function", "doc": "<p>This method builds the property by reading the corresponding SMT-LIB file</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>filepath : str\n    Path to the SMT-LIB file\ninput_name : str, Optional\n    The name of the input vector\noutput_name : str, Optional\n    The name of the output vector</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">filepath</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">input_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;X&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">output_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;Y&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.verification.NeVerProperty.to_smt_file", "modulename": "pynever.strategies.verification", "qualname": "NeVerProperty.to_smt_file", "kind": "function", "doc": "<p>This method builds the SMT-LIB representation of the NeVerProperty, expressing\nthe variables and the matrices as constraints in the corresponding logic</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>input_id : str, Optional\n    Identifier of the input node (default: 'X')\noutput_id : str, Optional\n    Identifier of the output node (default: 'X')\nfilepath : str\n    Path to the SMT-LIB file to create</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_id</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;X&#39;</span>, </span><span class=\"param\"><span class=\"n\">output_id</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;Y&#39;</span>, </span><span class=\"param\"><span class=\"n\">filepath</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.verification.VerificationStrategy", "modulename": "pynever.strategies.verification", "qualname": "VerificationStrategy", "kind": "class", "doc": "<p>An abstract class used to represent a Verification Strategy.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>verify(NeuralNetwork, Property)\n    Verify that the neural network of interest satisfy the property given as argument\n    using a verification strategy determined in the concrete children.</p>\n", "bases": "abc.ABC"}, {"fullname": "pynever.strategies.verification.VerificationStrategy.verify", "modulename": "pynever.strategies.verification", "qualname": "VerificationStrategy.verify", "kind": "function", "doc": "<p>Verify that the neural network of interest satisfy the property given as argument\nusing a verification strategy determined in the concrete children.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to train.\nprop : Dataset\n    The property which the neural network must satisfy.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True is the neural network satisfy the property, False otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">prop</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">verification</span><span class=\"o\">.</span><span class=\"n\">Property</span></span><span class=\"return-annotation\">) -> (&lt;class &#x27;bool&#x27;&gt;, typing.Optional[pynever.tensor.Tensor]):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.verification.NeverVerification", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification", "kind": "class", "doc": "<p>Class used to represent the Never verification strategy.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>heuristic : str\n    Heuristic used to decide the refinement level of the ReLU abstraction.\n    At present can be only one of the following:\n    - given_flags: the neuron to be refined are selected referring to the list given in params\n    - best_n_neurons: for each star the best n neuron to refine are selected based on the loss of precision\n      the abstraction would incur using the coarse over_approximation.\n    - overapprox: no neuron refinement.\n    - complete: full neuron refinement.\n    - mixed: equal number of neuron refined in each ReLU Layer.</p>\n\n<p>params : List\n    Parameters for the heuristic of interest.\n    If the heuristic is given_flags then params is a list whose first element is the list of refinement flags.\n    If the heuristic is best_n_neurons then params is a list whose first element is the number of neurons to refine.</p>\n\n<p>refinement_level : int\n    Refinement level for the sigmoid abstraction.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>verify(NeuralNetwork, Property)\n    Verify that the neural network of interest satisfy the property given as argument.</p>\n", "bases": "VerificationStrategy"}, {"fullname": "pynever.strategies.verification.NeverVerification.__init__", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">heuristic</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;best_n_neurons&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">params</span><span class=\"p\">:</span> <span class=\"n\">List</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">refinement_level</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "pynever.strategies.verification.NeverVerification.heuristic", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.heuristic", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerification.params", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerification.refinement_level", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.refinement_level", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerification.logger", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.logger", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerification.counterexample_stars", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.counterexample_stars", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerification.layers_bounds", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.layers_bounds", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerification.verify", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.verify", "kind": "function", "doc": "<p>Entry point for the verification algorithm for a network and a property</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The network model in the internal representation\nprop : Property\n    The property specification</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True if the network is safe, False otherwise</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">prop</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">verification</span><span class=\"o\">.</span><span class=\"n\">Property</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.verification.NeverVerification.get_output_starset", "modulename": "pynever.strategies.verification", "qualname": "NeverVerification.get_output_starset", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">prop</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">verification</span><span class=\"o\">.</span><span class=\"n\">Property</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef", "kind": "class", "doc": "<p>Class used to represent the Never verification strategy with counter example guided refinement.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>max_neurons : int\n    Maximum number of neuron to refine.</p>\n\n<p>input_search_params : Dict\n    Parameters for the counter-example search.</p>\n\n<p>precision : float\n    Acceptable threshold for the counter-example search.</p>\n\n<p>rel_ref : bool\n    Flag for choosing between the RO and PS refinement methodologies.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>verify(NeuralNetwork, Property)\n    Verify that the neural network of interest satisfy the property given as argument.</p>\n", "bases": "VerificationStrategy"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.__init__", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">max_neurons</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_search_params</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">precision</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.005</span>,</span><span class=\"param\">\t<span class=\"n\">rel_ref</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.max_neurons", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.max_neurons", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.input_search_params", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.input_search_params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.precision", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.precision", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.heuristic", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.heuristic", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.params", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.logger", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.logger", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.rel_ref", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.rel_ref", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.verify", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.verify", "kind": "function", "doc": "<p>Verify that the neural network of interest satisfy the property given as argument\nusing a verification strategy determined in the concrete children.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The neural network to train.\nprop : Dataset\n    The property which the neural network must satisfy.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True is the neural network satisfy the property, False otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">prop</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">verification</span><span class=\"o\">.</span><span class=\"n\">Property</span></span><span class=\"return-annotation\">) -> (&lt;class &#x27;bool&#x27;&gt;, typing.Optional[pynever.tensor.Tensor]):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.verification.NeverVerificationRef.get_output_starset", "modulename": "pynever.strategies.verification", "qualname": "NeverVerificationRef.get_output_starset", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">prop</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">verification</span><span class=\"o\">.</span><span class=\"n\">Property</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.strategies.verification.LRPAnalyzer", "modulename": "pynever.strategies.verification", "qualname": "LRPAnalyzer", "kind": "class", "doc": "<p>Class used to represent the Layer-wise Relevance Propagation Algorithm used in the counter-example\nguided refinement. At present only works for fully connected layers and relu activation functions.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>lrp_rule: Callable, optional\n    Rule used for the LRP propagation: it should be a function which, when applied to the fully connected layers,\n    modify the weights as needed. It should work with our version of the Linear pytorch layers. (default: None)</p>\n\n<p>epsilon: float, optional\n    term used to avoid division by zero errors and to guarantee the behaviour 0/0 = 0. (default: 1e-9)</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>analyze(NeuralNetwork, Tensor)\n    Analyze the Neural Network with respect to the input Tensor of interest. It returns a list of list containing\n    the relevance value for the hidden layers ReLU neurons.</p>\n"}, {"fullname": "pynever.strategies.verification.LRPAnalyzer.__init__", "modulename": "pynever.strategies.verification", "qualname": "LRPAnalyzer.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lrp_rule</span><span class=\"p\">:</span> <span class=\"n\">Callable</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-09</span></span>)</span>"}, {"fullname": "pynever.strategies.verification.LRPAnalyzer.lrp_rule", "modulename": "pynever.strategies.verification", "qualname": "LRPAnalyzer.lrp_rule", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.LRPAnalyzer.epsilon", "modulename": "pynever.strategies.verification", "qualname": "LRPAnalyzer.epsilon", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "pynever.strategies.verification.LRPAnalyzer.analyze", "modulename": "pynever.strategies.verification", "qualname": "LRPAnalyzer.analyze", "kind": "function", "doc": "<p>Analyze the Neural Network with respect to the input Tensor of interest. It returns a list of list containing\nthe relevance value for the hidden layers ReLU neurons.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The network to analyze to extract the relevances of the ReLU neurons.\nsample : Tensor\n    The data sample which is used to compute the relevances.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>List\n    List containing the relevances for each neuron of each ReLU hidden layer.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">sample</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.tensor", "modulename": "pynever.tensor", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.tensor.Tensor", "modulename": "pynever.tensor", "qualname": "Tensor", "kind": "class", "doc": "<p>Our internal representation of a Tensor. Right now it just inherits from the class ndarray of the numpy library.</p>\n", "bases": "numpy.ndarray"}, {"fullname": "pynever.tests", "modulename": "pynever.tests", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.tests.conversion_test", "modulename": "pynever.tests.conversion_test", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.tests.conversion_test.float_tolerance", "modulename": "pynever.tests.conversion_test", "qualname": "float_tolerance", "kind": "variable", "doc": "<p></p>\n", "default_value": "1e-05"}, {"fullname": "pynever.tests.conversion_test.relu_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "relu_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.sigmoid_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "sigmoid_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.fully_connected_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "fully_connected_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span>,</span><span class=\"param\">\t<span class=\"n\">has_bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.batchnorm_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "batchnorm_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.conv_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "conv_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span>,</span><span class=\"param\">\t<span class=\"n\">has_bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.averagepool_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "averagepool_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.maxpool_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "maxpool_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.lrn_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "lrn_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.softmax_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "softmax_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.unsqueeze_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "unsqueeze_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.reshape_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "reshape_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.flatten_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "flatten_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.dropout_node_test", "modulename": "pynever.tests.conversion_test", "qualname": "dropout_node_test", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">converter</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">conversion</span><span class=\"o\">.</span><span class=\"n\">ConversionStrategy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.tests.conversion_test.converters", "modulename": "pynever.tests.conversion_test", "qualname": "converters", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&lt;pynever.strategies.conversion.ONNXConverter object&gt;, &lt;pynever.strategies.conversion.PyTorchConverter object&gt;]"}, {"fullname": "pynever.utilities", "modulename": "pynever.utilities", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "pynever.utilities.logger_name", "modulename": "pynever.utilities", "qualname": "logger_name", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;pynever.utilities&#x27;"}, {"fullname": "pynever.utilities.execute_network", "modulename": "pynever.utilities", "qualname": "execute_network", "kind": "function", "doc": "<p>Apply the neural network function to an input Tensor\nusing pyTorch backend</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : NeuralNetwork\n    The network to evaluate\nnet_input : Tensor\n    The input value to feed</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>Tensor\n    The computed output</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">net_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.combine_batchnorm1d", "modulename": "pynever.utilities", "qualname": "combine_batchnorm1d", "kind": "function", "doc": "<p>Utility function to combine a BatchNorm1D node with a Linear node in a corresponding Linear node.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>linear : Linear\n    Linear to combine.\nbatchnorm : BatchNorm1D\n    BatchNorm1D to combine.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>Linear\n    The Linear resulting from the fusion of the two input nodes.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">linear</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">pytorch_layers</span><span class=\"o\">.</span><span class=\"n\">Linear</span>,</span><span class=\"param\">\t<span class=\"n\">batchnorm</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">pytorch_layers</span><span class=\"o\">.</span><span class=\"n\">BatchNorm1d</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">pytorch_layers</span><span class=\"o\">.</span><span class=\"n\">Linear</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.combine_batchnorm1d_net", "modulename": "pynever.utilities", "qualname": "combine_batchnorm1d_net", "kind": "function", "doc": "<p>Utilities function to combine all the FullyConnectedNodes followed by BatchNorm1DNodes in corresponding\nFullyConnectedNodes.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>network : SequentialNetwork\n    Sequential Network of interest of which we want to combine the nodes.</p>\n\n<h2 id=\"return\">Return</h2>\n\n<p>SequentialNetwork\n    Corresponding Sequential Network with the combined nodes.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">SequentialNetwork</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">SequentialNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.generate_linf_robustness_query", "modulename": "pynever.utilities", "qualname": "generate_linf_robustness_query", "kind": "function", "doc": "<p>Function to generate a Robustness SMTLIB query and to save it to a SMTLIB file.\nThe robustness query is of the kind based on the infinity norm.\nIt assumes that the data and target are from a classification task.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data : Tensor\n    Input data of interest.\nadv_target : int\n    Desired adversarial target for the input data.\nbounds : (int, int)\n    Bounds for the input data (lower_bound, upper_bound).\nnum_classes : int\n    Number of possible classes.\nepsilon : float\n    Perturbation with respect to the infinity norm.\nfilepath : str\n    Filepath for the resulting SMTLIB file.\ntargeted : bool\n    Flag for targeted/untargeted robustness query</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">adv_target</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">bounds</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span>,</span><span class=\"param\">\t<span class=\"n\">num_classes</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">epsilon</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">filepath</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">targeted</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.parse_linf_robustness_smtlib", "modulename": "pynever.utilities", "qualname": "parse_linf_robustness_smtlib", "kind": "function", "doc": "<p>Function to extract the parameters of a robustness query from the smtlib file.\nIt assumes the SMTLIB file is structured as following:</p>\n\n<pre><code>; definition of the variables of interest\n(declare-const X_0 Real)\n(declare-const X_1 Real)\n...\n(declare-const Y_1 Real)\n(declare-const Y_2 Real)\n...\n; definition of the constraints\n(assert (&gt;= X_0 eps_0))\n(assert (&lt;= X_0 eps_1))\n...\n(assert (&lt;= (- Y_0 Y_1) 0))\n...\n</code></pre>\n\n<p>Where the eps_i are Real numbers.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>filepath : str\n    Filepath to the SMTLIB file.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>(bool, list, int)\n    Tuple of list: the first list contains the values eps_i for each variable as tuples (lower_bound, upper_bound),\n    while the int correspond to the desired target for the related data.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">filepath</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.net_update", "modulename": "pynever.utilities", "qualname": "net_update", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">network</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>:</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.parse_acas_property", "modulename": "pynever.utilities", "qualname": "parse_acas_property", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filepath</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> ((&lt;class &#x27;pynever.tensor.Tensor&#x27;&gt;, &lt;class &#x27;pynever.tensor.Tensor&#x27;&gt;), (&lt;class &#x27;pynever.tensor.Tensor&#x27;&gt;, &lt;class &#x27;pynever.tensor.Tensor&#x27;&gt;)):</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.parse_nnet", "modulename": "pynever.utilities", "qualname": "parse_nnet", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">filepath</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> (&lt;class &#x27;list&#x27;&gt;, &lt;class &#x27;list&#x27;&gt;, &lt;class &#x27;list&#x27;&gt;, &lt;class &#x27;list&#x27;&gt;, &lt;class &#x27;list&#x27;&gt;, &lt;class &#x27;list&#x27;&gt;):</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.input_search", "modulename": "pynever.utilities", "qualname": "input_search", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">net</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">ref_output</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">start_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">max_iter</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">threshold</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span>,</span><span class=\"param\">\toptimizer_con: type = &lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">opt_params</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tscheduler_con: type = &lt;class &#x27;torch.optim.lr_scheduler.ReduceLROnPlateau&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">scheduler_params</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_iter_no_change</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.input_search_cloud", "modulename": "pynever.utilities", "qualname": "input_search_cloud", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">net</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">ref_output</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">start_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">max_iter</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">scale_coeff</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">iter_change_scale</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">iter_early_stop</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">adjustment_rate</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">num_samples</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>,</span><span class=\"param\">\t<span class=\"n\">threshold</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.search_cloud", "modulename": "pynever.utilities", "qualname": "search_cloud", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">net</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">ref_output</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">start_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_samples</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">scale</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.input_search_lbl", "modulename": "pynever.utilities", "qualname": "input_search_lbl", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">net</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">SequentialNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">ref_output</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">starset_list</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">strategies</span><span class=\"o\">.</span><span class=\"n\">abstraction</span><span class=\"o\">.</span><span class=\"n\">StarSet</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">max_iter</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">threshold</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span>,</span><span class=\"param\">\toptimizer_con: type = &lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">opt_params</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tscheduler_con: type = &lt;class &#x27;torch.optim.lr_scheduler.ReduceLROnPlateau&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">scheduler_params</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_iter_no_change</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "pynever.utilities.compute_saliency", "modulename": "pynever.utilities", "qualname": "compute_saliency", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">net</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">networks</span><span class=\"o\">.</span><span class=\"n\">NeuralNetwork</span>,</span><span class=\"param\">\t<span class=\"n\">ref_input</span><span class=\"p\">:</span> <span class=\"n\">pynever</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();