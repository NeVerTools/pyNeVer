{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# API - Training\n",
    "\n",
    "This notebook illustrates the main features of pyNeVer for training a network on a dataset\n"
   ],
   "id": "813da955d6f3852b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The _datasets_ module\n",
    "\n",
    "The module *datasets* contains the classes to load a pre-defined dataset or a custom one."
   ],
   "id": "be86cf33b279daa8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "from pynever import datasets\n",
    "\n",
    "\"\"\"We provide a direct interface to the common MNIST and Fashion MNIST datasets\"\"\"\n",
    "\n",
    "# Prepare the dataset with a transformation to use it with a fully connected network\n",
    "transform = tr.Compose([tr.ToTensor(), tr.Normalize(1, 0.5), tr.Lambda(lambda x: torch.flatten(x))])\n",
    "mnist_training = datasets.TorchMNIST('path_to_data', train=True,\n",
    "                                     transform=transform)  # The dataset is downloaded if not found in the given path\n",
    "mnist_test = datasets.TorchMNIST('path_to_data', train=False, transform=transform)\n",
    "fmnist_test = datasets.TorchFMNIST('path_to_data', train=False)  # Here there is no transform applied"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is also possible to load a custom dataset stored as a plaintext file using the class __GenericFileDataset__. It requires the delimiter character (',' by default), the data type (float by default) and the target index, i.e., the position that separates the inputs from the outputs.",
   "id": "a118260c2ed0f250"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This dataset has ten inputs and is delimited by ';'\n",
    "my_custom_dataset = datasets.GenericFileDataset('dataset.txt', 10, dtype=float, delimiter=';')"
   ],
   "id": "d2e430052e8e170d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The _training_ module\n",
    "\n",
    "Once a dataset is loaded, it is possible to train a network with the same inputs and outputs. The training and testing strategies are initialized with all the necessary parameters before launch"
   ],
   "id": "22d24172c860181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pynever.networks import SequentialNetwork\n",
    "from pynever.nodes import FullyConnectedNode, ReLUNode\n",
    "from pynever.strategies.training import PytorchTraining, PytorchTesting\n",
    "\n",
    "mnist_net = SequentialNetwork('MNIST_net', 'X')\n",
    "mnist_net.append_node(FullyConnectedNode('fc', (784,), 1000))  # Shallow NN with 1000 ReLU neurons\n",
    "mnist_net.append_node(ReLUNode('relu', (1000,)))\n",
    "mnist_net.append_node(FullyConnectedNode('fc2', (1000,), 10))\n",
    "\n",
    "# The training strategy is derived from pyTorch\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from pynever.strategies.training import PytorchMetrics\n",
    "\n",
    "train_batch_size = 128\n",
    "validation_batch_size = 64\n",
    "test_batch_size = 64\n",
    "validation_percentage = 0.3\n",
    "opt_params = {'lr': 0.01}\n",
    "sch_params = {}\n",
    "\n",
    "# Capture logger\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger('pynever.strategies.training')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "training_strategy = PytorchTraining(Adam, opt_params, CrossEntropyLoss(), 10,\n",
    "                                    validation_percentage, train_batch_size, validation_batch_size,\n",
    "                                    scheduler_con=lr_scheduler.ReduceLROnPlateau, sch_params=sch_params,\n",
    "                                    precision_metric=PytorchMetrics.inaccuracy, device='cpu')\n",
    "trained_net = training_strategy.train(mnist_net, mnist_training)\n",
    "\n",
    "# Now, to test the results...\n",
    "test_strategy = PytorchTesting(PytorchMetrics.inaccuracy, {}, test_batch_size, 'cpu')\n",
    "test_strategy.test(trained_net, mnist_test)"
   ],
   "id": "4e46bdc13177fc08",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
